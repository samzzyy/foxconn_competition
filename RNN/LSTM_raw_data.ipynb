{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.fftpack import fft,ifft\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_plot(y_real,y_predict):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(range(len(y_real)),y_real, color='r')\n",
    "    ax.plot(range(len(y_predict)),y_predict, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "\n",
    "def load_train_fft_data(data_dire_list,sensor_channel=\"vibration_1\"):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,12800)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    window=25600\n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            fft_train_data_60s=np.array([]).reshape(-1,12800)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5]*seconds_counts).reshape(-1,60,1),axis=0)\n",
    "            for _ in range(60):\n",
    "                freqs=np.fft.fft(df_60s[sensor_channel][window*_:window*(_+1)])\n",
    "                freqs=freqs[0:12800].reshape(-1,12800)\n",
    "                fft_train_data_60s=np.append(fft_train_data_60s,freqs)\n",
    "            train_data_pool_array=np.append(train_data_pool_array,fft_train_data_60s.reshape(-1,60,12800),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "\n",
    "    label_filename = os.path.join(mkdtemp(), 'label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data\n",
    "def load_test_fft_data(data_dire_list,tool_age_list,sensor_channel=\"vibration_1\"):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,12800)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    window=12800\n",
    "    for data_dire,index in zip(data_dire_list,range(len(data_dire_list))):\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            fft_train_data_60s=np.array([]).reshape(-1,12800)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5+tool_age_list[index]]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "#             print(data_dire,str(file_index)+'.csv',(file_list_length-file_index)*5+tool_age_list[index])\n",
    "            for _ in range(60):\n",
    "                freqs=np.fft.fft(df_60s[sensor_channel][window*_:window*(_+1)])\n",
    "                freqs=abs(freqs[0:12800].reshape(-1,12800))\n",
    "                fft_train_data_60s=np.append(fft_train_data_60s,freqs)\n",
    "            train_data_pool_array=np.append(train_data_pool_array,fft_train_data_60s.reshape(-1,60,12800),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'test_source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'test_label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "def load_train_data(data_dire_list):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,25600)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "            train_data_pool_array=np.append(train_data_pool_array,df_60s['vibration_1'].values.reshape(-1,60,25600),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data\n",
    "def load_test_data(data_dire_list,tool_age_list):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,25600)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    for data_dire,index in zip(data_dire_list,range(len(data_dire_list))):\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5+tool_age_list[index]]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "            train_data_pool_array=np.append(train_data_pool_array,df_60s['vibration_1'].values.reshape(-1,60,25600),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'test_source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'test_label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dire = \"../../01-TrainingData-additional/\"\n",
    "source_dire_list=[\n",
    "    \"../../01-TrainingData-additional/01/\",\n",
    "    \"../../01-TrainingData-additional/02/\",\n",
    "  \"../../01-TrainingData-additional/03/\"\n",
    "]\n",
    "test_dire = \"../../02-TestingData-keD1/\"\n",
    "test_dire_list=[\n",
    "    \"../../02-TestingData-keD1/01/\",\n",
    "    \"../../02-TestingData-keD1/02/\",\n",
    "  \"../../02-TestingData-keD1/03/\",\n",
    "    \"../../02-TestingData-keD1/04/\",\n",
    "    \"../../02-TestingData-keD1/05/\"\n",
    "]\n",
    "tool_age_list=[104,52,190,66,40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4181"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,train_label=load_train_data(source_dire_list)\n",
    "valid_data,valid_label=load_test_data(test_dire_list,tool_age_list)\n",
    "\n",
    "# train_fft_data,train_label=load_train_fft_data(source_dire_list)\n",
    "# valid_fft_data,valid_label=load_test_fft_data(test_dire_list,tool_age_list)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras import models as M\n",
    "from keras import layers as L\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(y_true, y_pred):\n",
    "    y_true, y_pred = tf.reshape(y_true, [-1]), tf.reshape(y_pred, [-1])\n",
    "    er = y_true - y_pred\n",
    "    mask_n, mask_p = (er<=0), (er>0)\n",
    "    er_n, er_p = tf.boolean_mask(er, mask_n), tf.boolean_mask(er, mask_p)\n",
    "    score_n = tf.exp(-tf.log(0.5)*er_n/5)\n",
    "    score_p = tf.exp(tf.log(0.5)*er_p/20)\n",
    "    score = tf.concat([score_n, score_p], 0)\n",
    "    score = tf.reduce_mean(score)*100\n",
    "    return score\n",
    "def cust_loss1(y_real,y_predicted):\n",
    "    y_diff = y_real - y_predicted\n",
    "    loss = tf.where(tf.greater(y_diff, 0),\n",
    "                    -tf.exp(tf.log(0.5) * (y_diff / 20)) +1,\n",
    "                    -tf.exp(-tf.log(0.5) * (y_diff / 5)) +1)\n",
    "    return loss*tf.reduce_max(abs(y_diff))\n",
    "def cust_loss2(y_real,y_predicted):\n",
    "    y_diff = y_real - y_predicted\n",
    "    loss = tf.where(tf.greater(y_diff, 0),\n",
    "                    -tf.log(0.5) * (y_diff / 20),\n",
    "                    tf.log(0.5) * (y_diff / 5))\n",
    "    return loss**2\n",
    "def Error_compute(y_real,y_predicted):\n",
    "    y_diff=y_real-y_predicted\n",
    "    diff_positive=y_diff[y_diff>0]\n",
    "    diff_negitive_0=y_diff[y_diff<=0]\n",
    "    if diff_negitive_0.shape[0] >0:\n",
    "        sum_negitive_error=sum(np.exp(-np.log(0.5)*(diff_negitive_0/5)))\n",
    "    else:\n",
    "        sum_negitive_error=0\n",
    "    if diff_positive.shape[0] >0:\n",
    "        sum_positive_error=sum(np.exp(np.log(0.5)*(diff_positive/20)))\n",
    "    else:\n",
    "        sum_positive_error=0\n",
    "    return (sum_negitive_error+sum_positive_error)/len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "graph = None\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape):\n",
    "    x_input = L.Input(shape=input_shape)\n",
    "    x=L.LSTM(units=300,activation=\"tanh\",return_sequences=True)(x_input)#320\n",
    "    x=L.TimeDistributed(L.Dense(150))(x)\n",
    "    x=L.Dropout(0.5)(x)\n",
    "    x=L.LSTM(units=60,activation=\"tanh\",return_sequences=True)(x)\n",
    "    y=L.TimeDistributed(L.Dense(1))(x)\n",
    "    \n",
    "    model = M.Model(inputs=x_input, outputs=y, name=\"LSTM\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 12800)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 300)           15721200  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 5)             1505      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 5)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 60)            15840     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 15,738,606\n",
      "Trainable params: 15,738,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"./lstm_raw_fft.h5\",monitor='val_evaluation_metric',verbose=1,save_best_only='True',\n",
    "                             mode='max',period=1)\n",
    "# tensorboard = TensorBoard(log_dir='log(./)')\n",
    "callback_lists = [checkpoint]  #因为callback是list型,必须转化为list\n",
    "graph = tf.get_default_graph()\n",
    "model=LSTM_model((60,12800))\n",
    "model.summary()\n",
    "# model=LSTM_model((60,12800))\n",
    "Adam = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam,metrics=[evaluation_metric])\n",
    "# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\n",
    "model.fit(train_fft_data,train_label, epochs=1000, verbose=2,batch_size=25,\n",
    "          validation_data=(valid_fft_data, valid_label),callbacks=callback_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 25600)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 300)           31081200  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 150)           45150     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 60)            50640     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 31,177,051\n",
      "Trainable params: 31,177,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 133 samples, validate on 50 samples\n",
      "Epoch 1/2000\n",
      " - 14s - loss: 15978.4006 - evaluation_metric: 14.9585 - val_loss: 14711.9209 - val_evaluation_metric: 6.7677\n",
      "\n",
      "Epoch 00001: val_evaluation_metric improved from -inf to 6.76770, saving model to ./lstm_raw.h5\n",
      "Epoch 2/2000\n",
      " - 9s - loss: 15187.2276 - evaluation_metric: 15.1297 - val_loss: 14148.8560 - val_evaluation_metric: 7.4262\n",
      "\n",
      "Epoch 00002: val_evaluation_metric improved from 6.76770 to 7.42617, saving model to ./lstm_raw.h5\n",
      "Epoch 3/2000\n",
      " - 10s - loss: 14737.6305 - evaluation_metric: 15.5339 - val_loss: 13908.0811 - val_evaluation_metric: 7.7503\n",
      "\n",
      "Epoch 00003: val_evaluation_metric improved from 7.42617 to 7.75032, saving model to ./lstm_raw.h5\n",
      "Epoch 4/2000\n",
      " - 12s - loss: 14520.8956 - evaluation_metric: 15.6942 - val_loss: 13784.9585 - val_evaluation_metric: 7.9133\n",
      "\n",
      "Epoch 00004: val_evaluation_metric improved from 7.75032 to 7.91333, saving model to ./lstm_raw.h5\n",
      "Epoch 5/2000\n",
      " - 11s - loss: 14404.7563 - evaluation_metric: 15.8367 - val_loss: 13701.2979 - val_evaluation_metric: 8.0264\n",
      "\n",
      "Epoch 00005: val_evaluation_metric improved from 7.91333 to 8.02641, saving model to ./lstm_raw.h5\n",
      "Epoch 6/2000\n",
      " - 12s - loss: 14318.9032 - evaluation_metric: 15.8495 - val_loss: 13620.4761 - val_evaluation_metric: 8.1366\n",
      "\n",
      "Epoch 00006: val_evaluation_metric improved from 8.02641 to 8.13661, saving model to ./lstm_raw.h5\n",
      "Epoch 7/2000\n",
      " - 12s - loss: 14238.8903 - evaluation_metric: 15.7779 - val_loss: 13536.5879 - val_evaluation_metric: 8.2534\n",
      "\n",
      "Epoch 00007: val_evaluation_metric improved from 8.13661 to 8.25338, saving model to ./lstm_raw.h5\n",
      "Epoch 8/2000\n",
      " - 12s - loss: 14156.4842 - evaluation_metric: 15.7506 - val_loss: 13455.9150 - val_evaluation_metric: 8.3678\n",
      "\n",
      "Epoch 00008: val_evaluation_metric improved from 8.25338 to 8.36782, saving model to ./lstm_raw.h5\n",
      "Epoch 9/2000\n",
      " - 13s - loss: 14076.0220 - evaluation_metric: 15.7705 - val_loss: 13376.3755 - val_evaluation_metric: 8.4824\n",
      "\n",
      "Epoch 00009: val_evaluation_metric improved from 8.36782 to 8.48243, saving model to ./lstm_raw.h5\n",
      "Epoch 10/2000\n",
      " - 12s - loss: 14000.2402 - evaluation_metric: 15.7924 - val_loss: 13296.8857 - val_evaluation_metric: 8.5990\n",
      "\n",
      "Epoch 00010: val_evaluation_metric improved from 8.48243 to 8.59905, saving model to ./lstm_raw.h5\n",
      "Epoch 11/2000\n",
      " - 14s - loss: 13921.6996 - evaluation_metric: 15.7666 - val_loss: 13219.8193 - val_evaluation_metric: 8.7141\n",
      "\n",
      "Epoch 00011: val_evaluation_metric improved from 8.59905 to 8.71409, saving model to ./lstm_raw.h5\n",
      "Epoch 12/2000\n",
      " - 14s - loss: 13847.8991 - evaluation_metric: 15.8075 - val_loss: 13142.5176 - val_evaluation_metric: 8.8315\n",
      "\n",
      "Epoch 00012: val_evaluation_metric improved from 8.71409 to 8.83149, saving model to ./lstm_raw.h5\n",
      "Epoch 13/2000\n",
      " - 13s - loss: 13775.5019 - evaluation_metric: 15.8021 - val_loss: 13067.3711 - val_evaluation_metric: 8.9476\n",
      "\n",
      "Epoch 00013: val_evaluation_metric improved from 8.83149 to 8.94757, saving model to ./lstm_raw.h5\n",
      "Epoch 14/2000\n",
      " - 14s - loss: 13703.5373 - evaluation_metric: 15.8935 - val_loss: 12994.2207 - val_evaluation_metric: 9.0625\n",
      "\n",
      "Epoch 00014: val_evaluation_metric improved from 8.94757 to 9.06246, saving model to ./lstm_raw.h5\n",
      "Epoch 15/2000\n",
      " - 14s - loss: 13634.0680 - evaluation_metric: 15.9180 - val_loss: 12922.2612 - val_evaluation_metric: 9.1774\n",
      "\n",
      "Epoch 00015: val_evaluation_metric improved from 9.06246 to 9.17735, saving model to ./lstm_raw.h5\n",
      "Epoch 16/2000\n",
      " - 13s - loss: 13563.8296 - evaluation_metric: 15.9637 - val_loss: 12851.5293 - val_evaluation_metric: 9.2921\n",
      "\n",
      "Epoch 00016: val_evaluation_metric improved from 9.17735 to 9.29212, saving model to ./lstm_raw.h5\n",
      "Epoch 17/2000\n",
      " - 14s - loss: 13494.4427 - evaluation_metric: 16.0322 - val_loss: 12781.1475 - val_evaluation_metric: 9.4082\n",
      "\n",
      "Epoch 00017: val_evaluation_metric improved from 9.29212 to 9.40817, saving model to ./lstm_raw.h5\n",
      "Epoch 18/2000\n",
      " - 15s - loss: 13426.8558 - evaluation_metric: 16.1143 - val_loss: 12711.3706 - val_evaluation_metric: 9.5251\n",
      "\n",
      "Epoch 00018: val_evaluation_metric improved from 9.40817 to 9.52509, saving model to ./lstm_raw.h5\n",
      "Epoch 19/2000\n",
      " - 14s - loss: 13358.9521 - evaluation_metric: 16.0569 - val_loss: 12641.7988 - val_evaluation_metric: 9.6435\n",
      "\n",
      "Epoch 00019: val_evaluation_metric improved from 9.52509 to 9.64354, saving model to ./lstm_raw.h5\n",
      "Epoch 20/2000\n",
      " - 15s - loss: 13291.7660 - evaluation_metric: 16.0358 - val_loss: 12572.4907 - val_evaluation_metric: 9.7635\n",
      "\n",
      "Epoch 00020: val_evaluation_metric improved from 9.64354 to 9.76345, saving model to ./lstm_raw.h5\n",
      "Epoch 21/2000\n",
      " - 13s - loss: 13224.5613 - evaluation_metric: 15.9764 - val_loss: 12503.8315 - val_evaluation_metric: 9.8842\n",
      "\n",
      "Epoch 00021: val_evaluation_metric improved from 9.76345 to 9.88415, saving model to ./lstm_raw.h5\n",
      "Epoch 22/2000\n",
      " - 14s - loss: 13157.8155 - evaluation_metric: 15.9664 - val_loss: 12435.4370 - val_evaluation_metric: 10.0063\n",
      "\n",
      "Epoch 00022: val_evaluation_metric improved from 9.88415 to 10.00632, saving model to ./lstm_raw.h5\n",
      "Epoch 23/2000\n",
      " - 10s - loss: 13091.7519 - evaluation_metric: 15.9766 - val_loss: 12367.8911 - val_evaluation_metric: 10.1289\n",
      "\n",
      "Epoch 00023: val_evaluation_metric improved from 10.00632 to 10.12892, saving model to ./lstm_raw.h5\n",
      "Epoch 24/2000\n",
      " - 9s - loss: 13027.4790 - evaluation_metric: 15.9398 - val_loss: 12301.2285 - val_evaluation_metric: 10.2518\n",
      "\n",
      "Epoch 00024: val_evaluation_metric improved from 10.12892 to 10.25183, saving model to ./lstm_raw.h5\n",
      "Epoch 25/2000\n",
      " - 9s - loss: 12962.8910 - evaluation_metric: 15.9808 - val_loss: 12235.2480 - val_evaluation_metric: 10.3754\n",
      "\n",
      "Epoch 00025: val_evaluation_metric improved from 10.25183 to 10.37540, saving model to ./lstm_raw.h5\n",
      "Epoch 26/2000\n",
      " - 11s - loss: 12899.0268 - evaluation_metric: 15.9958 - val_loss: 12170.4409 - val_evaluation_metric: 10.4987\n",
      "\n",
      "Epoch 00026: val_evaluation_metric improved from 10.37540 to 10.49867, saving model to ./lstm_raw.h5\n",
      "Epoch 27/2000\n",
      " - 11s - loss: 12836.8929 - evaluation_metric: 16.0001 - val_loss: 12104.2759 - val_evaluation_metric: 10.6265\n",
      "\n",
      "Epoch 00027: val_evaluation_metric improved from 10.49867 to 10.62651, saving model to ./lstm_raw.h5\n",
      "Epoch 28/2000\n",
      " - 10s - loss: 12773.0468 - evaluation_metric: 16.0337 - val_loss: 12038.8765 - val_evaluation_metric: 10.7549\n",
      "\n",
      "Epoch 00028: val_evaluation_metric improved from 10.62651 to 10.75487, saving model to ./lstm_raw.h5\n",
      "Epoch 29/2000\n",
      " - 12s - loss: 12709.0239 - evaluation_metric: 16.0719 - val_loss: 11974.7729 - val_evaluation_metric: 10.8827\n",
      "\n",
      "Epoch 00029: val_evaluation_metric improved from 10.75487 to 10.88266, saving model to ./lstm_raw.h5\n",
      "Epoch 30/2000\n",
      " - 12s - loss: 12646.4376 - evaluation_metric: 16.1174 - val_loss: 11909.5552 - val_evaluation_metric: 11.0147\n",
      "\n",
      "Epoch 00030: val_evaluation_metric improved from 10.88266 to 11.01472, saving model to ./lstm_raw.h5\n",
      "Epoch 31/2000\n",
      " - 11s - loss: 12584.0318 - evaluation_metric: 16.1728 - val_loss: 11844.9502 - val_evaluation_metric: 11.1476\n",
      "\n",
      "Epoch 00031: val_evaluation_metric improved from 11.01472 to 11.14761, saving model to ./lstm_raw.h5\n",
      "Epoch 32/2000\n",
      " - 9s - loss: 12522.9107 - evaluation_metric: 16.2273 - val_loss: 11782.3623 - val_evaluation_metric: 11.2784\n",
      "\n",
      "Epoch 00032: val_evaluation_metric improved from 11.14761 to 11.27837, saving model to ./lstm_raw.h5\n",
      "Epoch 33/2000\n",
      " - 13s - loss: 12463.9146 - evaluation_metric: 16.2526 - val_loss: 11719.8374 - val_evaluation_metric: 11.4110\n",
      "\n",
      "Epoch 00033: val_evaluation_metric improved from 11.27837 to 11.41100, saving model to ./lstm_raw.h5\n",
      "Epoch 34/2000\n",
      " - 9s - loss: 12401.0949 - evaluation_metric: 16.1908 - val_loss: 11659.2480 - val_evaluation_metric: 11.5415\n",
      "\n",
      "Epoch 00034: val_evaluation_metric improved from 11.41100 to 11.54150, saving model to ./lstm_raw.h5\n",
      "Epoch 35/2000\n",
      " - 11s - loss: 12341.8098 - evaluation_metric: 16.1655 - val_loss: 11598.8545 - val_evaluation_metric: 11.6735\n",
      "\n",
      "Epoch 00035: val_evaluation_metric improved from 11.54150 to 11.67353, saving model to ./lstm_raw.h5\n",
      "Epoch 36/2000\n",
      " - 9s - loss: 12283.7444 - evaluation_metric: 16.1206 - val_loss: 11536.4131 - val_evaluation_metric: 11.8121\n",
      "\n",
      "Epoch 00036: val_evaluation_metric improved from 11.67353 to 11.81213, saving model to ./lstm_raw.h5\n",
      "Epoch 37/2000\n",
      " - 10s - loss: 12223.3663 - evaluation_metric: 16.0628 - val_loss: 11474.2139 - val_evaluation_metric: 11.9524\n",
      "\n",
      "Epoch 00037: val_evaluation_metric improved from 11.81213 to 11.95236, saving model to ./lstm_raw.h5\n",
      "Epoch 38/2000\n",
      " - 9s - loss: 12163.1059 - evaluation_metric: 16.0768 - val_loss: 11411.8462 - val_evaluation_metric: 12.0952\n",
      "\n",
      "Epoch 00038: val_evaluation_metric improved from 11.95236 to 12.09517, saving model to ./lstm_raw.h5\n",
      "Epoch 39/2000\n",
      " - 11s - loss: 12103.3219 - evaluation_metric: 16.0356 - val_loss: 11348.8589 - val_evaluation_metric: 12.2417\n",
      "\n",
      "Epoch 00039: val_evaluation_metric improved from 12.09517 to 12.24170, saving model to ./lstm_raw.h5\n",
      "Epoch 40/2000\n",
      " - 12s - loss: 12043.2174 - evaluation_metric: 16.0966 - val_loss: 11287.4951 - val_evaluation_metric: 12.3867\n",
      "\n",
      "Epoch 00040: val_evaluation_metric improved from 12.24170 to 12.38671, saving model to ./lstm_raw.h5\n",
      "Epoch 41/2000\n",
      " - 14s - loss: 11983.6995 - evaluation_metric: 16.0654 - val_loss: 11226.8687 - val_evaluation_metric: 12.5322\n",
      "\n",
      "Epoch 00041: val_evaluation_metric improved from 12.38671 to 12.53222, saving model to ./lstm_raw.h5\n",
      "Epoch 42/2000\n",
      " - 13s - loss: 11924.8310 - evaluation_metric: 16.1191 - val_loss: 11166.7646 - val_evaluation_metric: 12.6787\n",
      "\n",
      "Epoch 00042: val_evaluation_metric improved from 12.53222 to 12.67870, saving model to ./lstm_raw.h5\n",
      "Epoch 43/2000\n",
      " - 14s - loss: 11866.9880 - evaluation_metric: 16.1233 - val_loss: 11106.5786 - val_evaluation_metric: 12.8277\n",
      "\n",
      "Epoch 00043: val_evaluation_metric improved from 12.67870 to 12.82767, saving model to ./lstm_raw.h5\n",
      "Epoch 44/2000\n",
      " - 14s - loss: 11809.6199 - evaluation_metric: 16.2041 - val_loss: 11046.8325 - val_evaluation_metric: 12.9779\n",
      "\n",
      "Epoch 00044: val_evaluation_metric improved from 12.82767 to 12.97786, saving model to ./lstm_raw.h5\n",
      "Epoch 45/2000\n",
      " - 13s - loss: 11752.1579 - evaluation_metric: 16.1995 - val_loss: 10989.0996 - val_evaluation_metric: 13.1252\n",
      "\n",
      "Epoch 00045: val_evaluation_metric improved from 12.97786 to 13.12520, saving model to ./lstm_raw.h5\n",
      "Epoch 46/2000\n",
      " - 9s - loss: 11695.8560 - evaluation_metric: 16.2534 - val_loss: 10930.7446 - val_evaluation_metric: 13.2764\n",
      "\n",
      "Epoch 00046: val_evaluation_metric improved from 13.12520 to 13.27639, saving model to ./lstm_raw.h5\n",
      "Epoch 47/2000\n",
      " - 9s - loss: 11640.7522 - evaluation_metric: 16.3067 - val_loss: 10871.4268 - val_evaluation_metric: 13.4325\n",
      "\n",
      "Epoch 00047: val_evaluation_metric improved from 13.27639 to 13.43246, saving model to ./lstm_raw.h5\n",
      "Epoch 48/2000\n",
      " - 10s - loss: 11583.3321 - evaluation_metric: 16.3075 - val_loss: 10814.0518 - val_evaluation_metric: 13.5857\n",
      "\n",
      "Epoch 00048: val_evaluation_metric improved from 13.43246 to 13.58575, saving model to ./lstm_raw.h5\n",
      "Epoch 49/2000\n",
      " - 10s - loss: 11527.4551 - evaluation_metric: 16.2389 - val_loss: 10757.3687 - val_evaluation_metric: 13.7395\n",
      "\n",
      "Epoch 00049: val_evaluation_metric improved from 13.58575 to 13.73948, saving model to ./lstm_raw.h5\n",
      "Epoch 50/2000\n",
      " - 10s - loss: 11472.8634 - evaluation_metric: 16.1925 - val_loss: 10700.5806 - val_evaluation_metric: 13.8958\n",
      "\n",
      "Epoch 00050: val_evaluation_metric improved from 13.73948 to 13.89583, saving model to ./lstm_raw.h5\n",
      "Epoch 51/2000\n",
      " - 10s - loss: 11418.6790 - evaluation_metric: 16.1336 - val_loss: 10643.1714 - val_evaluation_metric: 14.0563\n",
      "\n",
      "Epoch 00051: val_evaluation_metric improved from 13.89583 to 14.05631, saving model to ./lstm_raw.h5\n",
      "Epoch 52/2000\n",
      " - 10s - loss: 11363.4610 - evaluation_metric: 16.1416 - val_loss: 10586.8726 - val_evaluation_metric: 14.2161\n",
      "\n",
      "Epoch 00052: val_evaluation_metric improved from 14.05631 to 14.21614, saving model to ./lstm_raw.h5\n",
      "Epoch 53/2000\n",
      " - 11s - loss: 11309.7907 - evaluation_metric: 16.1118 - val_loss: 10528.1130 - val_evaluation_metric: 14.3852\n",
      "\n",
      "Epoch 00053: val_evaluation_metric improved from 14.21614 to 14.38523, saving model to ./lstm_raw.h5\n",
      "Epoch 54/2000\n",
      " - 10s - loss: 11253.1780 - evaluation_metric: 16.1247 - val_loss: 10470.6562 - val_evaluation_metric: 14.5537\n",
      "\n",
      "Epoch 00054: val_evaluation_metric improved from 14.38523 to 14.55369, saving model to ./lstm_raw.h5\n",
      "Epoch 55/2000\n",
      " - 11s - loss: 11195.9813 - evaluation_metric: 16.1059 - val_loss: 10410.8567 - val_evaluation_metric: 14.7316\n",
      "\n",
      "Epoch 00055: val_evaluation_metric improved from 14.55369 to 14.73159, saving model to ./lstm_raw.h5\n",
      "Epoch 56/2000\n",
      " - 11s - loss: 11139.2395 - evaluation_metric: 16.1376 - val_loss: 10353.5376 - val_evaluation_metric: 14.9048\n",
      "\n",
      "Epoch 00056: val_evaluation_metric improved from 14.73159 to 14.90485, saving model to ./lstm_raw.h5\n",
      "Epoch 57/2000\n",
      " - 12s - loss: 11083.9545 - evaluation_metric: 16.1369 - val_loss: 10297.2087 - val_evaluation_metric: 15.0778\n",
      "\n",
      "Epoch 00057: val_evaluation_metric improved from 14.90485 to 15.07779, saving model to ./lstm_raw.h5\n",
      "Epoch 58/2000\n",
      " - 13s - loss: 11028.9865 - evaluation_metric: 16.1923 - val_loss: 10240.2834 - val_evaluation_metric: 15.2553\n",
      "\n",
      "Epoch 00058: val_evaluation_metric improved from 15.07779 to 15.25531, saving model to ./lstm_raw.h5\n",
      "Epoch 59/2000\n",
      " - 13s - loss: 10974.7662 - evaluation_metric: 16.2038 - val_loss: 10181.7444 - val_evaluation_metric: 15.4408\n",
      "\n",
      "Epoch 00059: val_evaluation_metric improved from 15.25531 to 15.44081, saving model to ./lstm_raw.h5\n",
      "Epoch 60/2000\n",
      " - 13s - loss: 10919.4547 - evaluation_metric: 16.2474 - val_loss: 10125.2390 - val_evaluation_metric: 15.6227\n",
      "\n",
      "Epoch 00060: val_evaluation_metric improved from 15.44081 to 15.62275, saving model to ./lstm_raw.h5\n",
      "Epoch 61/2000\n",
      " - 12s - loss: 10864.5330 - evaluation_metric: 16.3267 - val_loss: 10070.8032 - val_evaluation_metric: 15.8008\n",
      "\n",
      "Epoch 00061: val_evaluation_metric improved from 15.62275 to 15.80076, saving model to ./lstm_raw.h5\n",
      "Epoch 62/2000\n",
      " - 13s - loss: 10810.8854 - evaluation_metric: 16.3557 - val_loss: 10016.9500 - val_evaluation_metric: 15.9796\n",
      "\n",
      "Epoch 00062: val_evaluation_metric improved from 15.80076 to 15.97957, saving model to ./lstm_raw.h5\n",
      "Epoch 63/2000\n",
      " - 13s - loss: 10760.5700 - evaluation_metric: 16.3265 - val_loss: 9961.2761 - val_evaluation_metric: 16.1673\n",
      "\n",
      "Epoch 00063: val_evaluation_metric improved from 15.97957 to 16.16731, saving model to ./lstm_raw.h5\n",
      "Epoch 64/2000\n",
      " - 13s - loss: 10706.4512 - evaluation_metric: 16.2382 - val_loss: 9907.1316 - val_evaluation_metric: 16.3528\n",
      "\n",
      "Epoch 00064: val_evaluation_metric improved from 16.16731 to 16.35276, saving model to ./lstm_raw.h5\n",
      "Epoch 65/2000\n",
      " - 15s - loss: 10654.4816 - evaluation_metric: 16.2265 - val_loss: 9854.0234 - val_evaluation_metric: 16.5375\n",
      "\n",
      "Epoch 00065: val_evaluation_metric improved from 16.35276 to 16.53746, saving model to ./lstm_raw.h5\n",
      "Epoch 66/2000\n",
      " - 13s - loss: 10602.9899 - evaluation_metric: 16.1982 - val_loss: 9802.1392 - val_evaluation_metric: 16.7206\n",
      "\n",
      "Epoch 00066: val_evaluation_metric improved from 16.53746 to 16.72064, saving model to ./lstm_raw.h5\n",
      "Epoch 67/2000\n",
      " - 14s - loss: 10553.4456 - evaluation_metric: 16.1790 - val_loss: 9749.9368 - val_evaluation_metric: 16.9077\n",
      "\n",
      "Epoch 00067: val_evaluation_metric improved from 16.72064 to 16.90773, saving model to ./lstm_raw.h5\n",
      "Epoch 68/2000\n",
      " - 14s - loss: 10504.2421 - evaluation_metric: 16.1424 - val_loss: 9697.6257 - val_evaluation_metric: 17.0981\n",
      "\n",
      "Epoch 00068: val_evaluation_metric improved from 16.90773 to 17.09808, saving model to ./lstm_raw.h5\n",
      "Epoch 69/2000\n",
      " - 10s - loss: 10453.4626 - evaluation_metric: 16.1424 - val_loss: 9646.6216 - val_evaluation_metric: 17.2865\n",
      "\n",
      "Epoch 00069: val_evaluation_metric improved from 17.09808 to 17.28648, saving model to ./lstm_raw.h5\n",
      "Epoch 70/2000\n",
      " - 10s - loss: 10404.9383 - evaluation_metric: 16.1433 - val_loss: 9594.5891 - val_evaluation_metric: 17.4816\n",
      "\n",
      "Epoch 00070: val_evaluation_metric improved from 17.28648 to 17.48159, saving model to ./lstm_raw.h5\n",
      "Epoch 71/2000\n",
      " - 10s - loss: 10354.7408 - evaluation_metric: 16.1644 - val_loss: 9542.8037 - val_evaluation_metric: 17.6788\n",
      "\n",
      "Epoch 00071: val_evaluation_metric improved from 17.48159 to 17.67877, saving model to ./lstm_raw.h5\n",
      "Epoch 72/2000\n",
      " - 10s - loss: 10305.2731 - evaluation_metric: 16.1568 - val_loss: 9492.1724 - val_evaluation_metric: 17.8745\n",
      "\n",
      "Epoch 00072: val_evaluation_metric improved from 17.67877 to 17.87449, saving model to ./lstm_raw.h5\n",
      "Epoch 73/2000\n",
      " - 10s - loss: 10257.9226 - evaluation_metric: 16.1950 - val_loss: 9442.5708 - val_evaluation_metric: 18.0691\n",
      "\n",
      "Epoch 00073: val_evaluation_metric improved from 17.87449 to 18.06909, saving model to ./lstm_raw.h5\n",
      "Epoch 74/2000\n",
      " - 11s - loss: 10208.8093 - evaluation_metric: 16.2095 - val_loss: 9393.3684 - val_evaluation_metric: 18.2650\n",
      "\n",
      "Epoch 00074: val_evaluation_metric improved from 18.06909 to 18.26501, saving model to ./lstm_raw.h5\n",
      "Epoch 75/2000\n",
      " - 11s - loss: 10163.0964 - evaluation_metric: 16.2515 - val_loss: 9343.7668 - val_evaluation_metric: 18.4655\n",
      "\n",
      "Epoch 00075: val_evaluation_metric improved from 18.26501 to 18.46547, saving model to ./lstm_raw.h5\n",
      "Epoch 76/2000\n",
      " - 11s - loss: 10113.2927 - evaluation_metric: 16.2916 - val_loss: 9294.0452 - val_evaluation_metric: 18.6694\n",
      "\n",
      "Epoch 00076: val_evaluation_metric improved from 18.46547 to 18.66943, saving model to ./lstm_raw.h5\n",
      "Epoch 77/2000\n",
      " - 12s - loss: 10065.6257 - evaluation_metric: 16.3368 - val_loss: 9244.1304 - val_evaluation_metric: 18.8773\n",
      "\n",
      "Epoch 00077: val_evaluation_metric improved from 18.66943 to 18.87732, saving model to ./lstm_raw.h5\n",
      "Epoch 78/2000\n",
      " - 12s - loss: 10019.3628 - evaluation_metric: 16.3541 - val_loss: 9192.9431 - val_evaluation_metric: 19.0938\n",
      "\n",
      "Epoch 00078: val_evaluation_metric improved from 18.87732 to 19.09380, saving model to ./lstm_raw.h5\n",
      "Epoch 79/2000\n",
      " - 12s - loss: 9968.6195 - evaluation_metric: 16.3011 - val_loss: 9144.7717 - val_evaluation_metric: 19.3007\n",
      "\n",
      "Epoch 00079: val_evaluation_metric improved from 19.09380 to 19.30066, saving model to ./lstm_raw.h5\n",
      "Epoch 80/2000\n",
      " - 12s - loss: 9923.6028 - evaluation_metric: 16.2146 - val_loss: 9095.7322 - val_evaluation_metric: 19.5144\n",
      "\n",
      "Epoch 00080: val_evaluation_metric improved from 19.30066 to 19.51442, saving model to ./lstm_raw.h5\n",
      "Epoch 81/2000\n",
      " - 12s - loss: 9875.6796 - evaluation_metric: 16.1973 - val_loss: 9046.9780 - val_evaluation_metric: 19.7302\n",
      "\n",
      "Epoch 00081: val_evaluation_metric improved from 19.51442 to 19.73016, saving model to ./lstm_raw.h5\n",
      "Epoch 82/2000\n",
      " - 14s - loss: 9829.5117 - evaluation_metric: 16.1950 - val_loss: 8998.6328 - val_evaluation_metric: 19.9474\n",
      "\n",
      "Epoch 00082: val_evaluation_metric improved from 19.73016 to 19.94736, saving model to ./lstm_raw.h5\n",
      "Epoch 83/2000\n",
      " - 12s - loss: 9783.5528 - evaluation_metric: 16.1636 - val_loss: 8951.1045 - val_evaluation_metric: 20.1641\n",
      "\n",
      "Epoch 00083: val_evaluation_metric improved from 19.94736 to 20.16412, saving model to ./lstm_raw.h5\n",
      "Epoch 84/2000\n",
      " - 12s - loss: 9737.5399 - evaluation_metric: 16.1447 - val_loss: 8903.7415 - val_evaluation_metric: 20.3834\n",
      "\n",
      "Epoch 00084: val_evaluation_metric improved from 20.16412 to 20.38337, saving model to ./lstm_raw.h5\n",
      "Epoch 85/2000\n",
      " - 13s - loss: 9691.5810 - evaluation_metric: 16.1516 - val_loss: 8856.6238 - val_evaluation_metric: 20.6048\n",
      "\n",
      "Epoch 00085: val_evaluation_metric improved from 20.38337 to 20.60476, saving model to ./lstm_raw.h5\n",
      "Epoch 86/2000\n",
      " - 11s - loss: 9646.9513 - evaluation_metric: 16.1577 - val_loss: 8810.0010 - val_evaluation_metric: 20.8271\n",
      "\n",
      "Epoch 00086: val_evaluation_metric improved from 20.60476 to 20.82711, saving model to ./lstm_raw.h5\n",
      "Epoch 87/2000\n",
      " - 12s - loss: 9602.0595 - evaluation_metric: 16.1611 - val_loss: 8762.5894 - val_evaluation_metric: 21.0566\n",
      "\n",
      "Epoch 00087: val_evaluation_metric improved from 20.82711 to 21.05665, saving model to ./lstm_raw.h5\n",
      "Epoch 88/2000\n",
      " - 14s - loss: 9556.6354 - evaluation_metric: 16.1653 - val_loss: 8715.0833 - val_evaluation_metric: 21.2902\n",
      "\n",
      "Epoch 00088: val_evaluation_metric improved from 21.05665 to 21.29017, saving model to ./lstm_raw.h5\n",
      "Epoch 89/2000\n",
      " - 14s - loss: 9511.5306 - evaluation_metric: 16.2015 - val_loss: 8668.7087 - val_evaluation_metric: 21.5216\n",
      "\n",
      "Epoch 00089: val_evaluation_metric improved from 21.29017 to 21.52162, saving model to ./lstm_raw.h5\n",
      "Epoch 90/2000\n",
      " - 10s - loss: 9467.7173 - evaluation_metric: 16.2190 - val_loss: 8622.3289 - val_evaluation_metric: 21.7566\n",
      "\n",
      "Epoch 00090: val_evaluation_metric improved from 21.52162 to 21.75660, saving model to ./lstm_raw.h5\n",
      "Epoch 91/2000\n",
      " - 9s - loss: 9423.0419 - evaluation_metric: 16.2671 - val_loss: 8577.0730 - val_evaluation_metric: 21.9893\n",
      "\n",
      "Epoch 00091: val_evaluation_metric improved from 21.75660 to 21.98934, saving model to ./lstm_raw.h5\n",
      "Epoch 92/2000\n",
      " - 9s - loss: 9378.7784 - evaluation_metric: 16.3072 - val_loss: 8532.6404 - val_evaluation_metric: 22.2212\n",
      "\n",
      "Epoch 00092: val_evaluation_metric improved from 21.98934 to 22.22123, saving model to ./lstm_raw.h5\n",
      "Epoch 93/2000\n",
      " - 10s - loss: 9337.6806 - evaluation_metric: 16.3451 - val_loss: 8487.6172 - val_evaluation_metric: 22.4498\n",
      "\n",
      "Epoch 00093: val_evaluation_metric improved from 22.22123 to 22.44976, saving model to ./lstm_raw.h5\n",
      "Epoch 94/2000\n",
      " - 9s - loss: 9294.2075 - evaluation_metric: 16.3292 - val_loss: 8444.5134 - val_evaluation_metric: 22.5846\n",
      "\n",
      "Epoch 00094: val_evaluation_metric improved from 22.44976 to 22.58463, saving model to ./lstm_raw.h5\n",
      "Epoch 95/2000\n",
      " - 8s - loss: 9253.3135 - evaluation_metric: 16.3307 - val_loss: 8400.9426 - val_evaluation_metric: 22.7260\n",
      "\n",
      "Epoch 00095: val_evaluation_metric improved from 22.58463 to 22.72599, saving model to ./lstm_raw.h5\n",
      "Epoch 96/2000\n",
      " - 8s - loss: 9213.2260 - evaluation_metric: 16.2418 - val_loss: 8358.4316 - val_evaluation_metric: 22.8697\n",
      "\n",
      "Epoch 00096: val_evaluation_metric improved from 22.72599 to 22.86969, saving model to ./lstm_raw.h5\n",
      "Epoch 97/2000\n",
      " - 8s - loss: 9172.3942 - evaluation_metric: 16.2063 - val_loss: 8316.3352 - val_evaluation_metric: 23.0176\n",
      "\n",
      "Epoch 00097: val_evaluation_metric improved from 22.86969 to 23.01758, saving model to ./lstm_raw.h5\n",
      "Epoch 98/2000\n",
      " - 7s - loss: 9130.4255 - evaluation_metric: 16.1968 - val_loss: 8274.1458 - val_evaluation_metric: 23.1711\n",
      "\n",
      "Epoch 00098: val_evaluation_metric improved from 23.01758 to 23.17114, saving model to ./lstm_raw.h5\n",
      "Epoch 99/2000\n",
      " - 8s - loss: 9091.4342 - evaluation_metric: 16.1664 - val_loss: 8231.7339 - val_evaluation_metric: 23.3297\n",
      "\n",
      "Epoch 00099: val_evaluation_metric improved from 23.17114 to 23.32970, saving model to ./lstm_raw.h5\n",
      "Epoch 100/2000\n",
      " - 12s - loss: 9050.4951 - evaluation_metric: 16.1629 - val_loss: 8190.3865 - val_evaluation_metric: 23.4897\n",
      "\n",
      "Epoch 00100: val_evaluation_metric improved from 23.32970 to 23.48971, saving model to ./lstm_raw.h5\n",
      "Epoch 101/2000\n",
      " - 9s - loss: 9011.7367 - evaluation_metric: 16.1449 - val_loss: 8148.8655 - val_evaluation_metric: 23.6558\n",
      "\n",
      "Epoch 00101: val_evaluation_metric improved from 23.48971 to 23.65576, saving model to ./lstm_raw.h5\n",
      "Epoch 102/2000\n",
      " - 11s - loss: 8970.8711 - evaluation_metric: 16.1675 - val_loss: 8109.4321 - val_evaluation_metric: 23.8185\n",
      "\n",
      "Epoch 00102: val_evaluation_metric improved from 23.65576 to 23.81846, saving model to ./lstm_raw.h5\n",
      "Epoch 103/2000\n",
      " - 11s - loss: 8932.7588 - evaluation_metric: 16.1540 - val_loss: 8068.9619 - val_evaluation_metric: 23.9905\n",
      "\n",
      "Epoch 00103: val_evaluation_metric improved from 23.81846 to 23.99047, saving model to ./lstm_raw.h5\n",
      "Epoch 104/2000\n",
      " - 10s - loss: 8893.9006 - evaluation_metric: 16.1668 - val_loss: 8027.7344 - val_evaluation_metric: 24.1710\n",
      "\n",
      "Epoch 00104: val_evaluation_metric improved from 23.99047 to 24.17095, saving model to ./lstm_raw.h5\n",
      "Epoch 105/2000\n",
      " - 10s - loss: 8855.8237 - evaluation_metric: 16.1756 - val_loss: 7985.8557 - val_evaluation_metric: 24.3597\n",
      "\n",
      "Epoch 00105: val_evaluation_metric improved from 24.17095 to 24.35973, saving model to ./lstm_raw.h5\n",
      "Epoch 106/2000\n",
      " - 11s - loss: 8814.8436 - evaluation_metric: 16.1967 - val_loss: 7945.8372 - val_evaluation_metric: 24.5452\n",
      "\n",
      "Epoch 00106: val_evaluation_metric improved from 24.35973 to 24.54524, saving model to ./lstm_raw.h5\n",
      "Epoch 107/2000\n",
      " - 13s - loss: 8777.5881 - evaluation_metric: 16.2065 - val_loss: 7906.1980 - val_evaluation_metric: 24.7339\n",
      "\n",
      "Epoch 00107: val_evaluation_metric improved from 24.54524 to 24.73392, saving model to ./lstm_raw.h5\n",
      "Epoch 108/2000\n",
      " - 13s - loss: 8740.0553 - evaluation_metric: 16.2667 - val_loss: 7867.2483 - val_evaluation_metric: 24.9241\n",
      "\n",
      "Epoch 00108: val_evaluation_metric improved from 24.73392 to 24.92413, saving model to ./lstm_raw.h5\n",
      "Epoch 109/2000\n",
      " - 11s - loss: 8703.5981 - evaluation_metric: 16.2867 - val_loss: 7827.4045 - val_evaluation_metric: 25.1237\n",
      "\n",
      "Epoch 00109: val_evaluation_metric improved from 24.92413 to 25.12366, saving model to ./lstm_raw.h5\n",
      "Epoch 110/2000\n",
      " - 14s - loss: 8664.6437 - evaluation_metric: 16.3520 - val_loss: 7788.2754 - val_evaluation_metric: 25.3209\n",
      "\n",
      "Epoch 00110: val_evaluation_metric improved from 25.12366 to 25.32095, saving model to ./lstm_raw.h5\n",
      "Epoch 111/2000\n",
      " - 15s - loss: 8626.9199 - evaluation_metric: 16.3737 - val_loss: 7750.2200 - val_evaluation_metric: 25.4294\n",
      "\n",
      "Epoch 00111: val_evaluation_metric improved from 25.32095 to 25.42939, saving model to ./lstm_raw.h5\n",
      "Epoch 112/2000\n",
      " - 13s - loss: 8590.1204 - evaluation_metric: 16.2843 - val_loss: 7711.8174 - val_evaluation_metric: 25.5445\n",
      "\n",
      "Epoch 00112: val_evaluation_metric improved from 25.42939 to 25.54447, saving model to ./lstm_raw.h5\n",
      "Epoch 113/2000\n",
      " - 12s - loss: 8554.3968 - evaluation_metric: 16.2481 - val_loss: 7673.2588 - val_evaluation_metric: 25.6670\n",
      "\n",
      "Epoch 00113: val_evaluation_metric improved from 25.54447 to 25.66702, saving model to ./lstm_raw.h5\n",
      "Epoch 114/2000\n",
      " - 11s - loss: 8517.1106 - evaluation_metric: 16.2219 - val_loss: 7633.8818 - val_evaluation_metric: 25.7994\n",
      "\n",
      "Epoch 00114: val_evaluation_metric improved from 25.66702 to 25.79936, saving model to ./lstm_raw.h5\n",
      "Epoch 115/2000\n",
      " - 7s - loss: 8480.0687 - evaluation_metric: 16.2199 - val_loss: 7595.0549 - val_evaluation_metric: 25.9369\n",
      "\n",
      "Epoch 00115: val_evaluation_metric improved from 25.79936 to 25.93689, saving model to ./lstm_raw.h5\n",
      "Epoch 116/2000\n",
      " - 10s - loss: 8443.5035 - evaluation_metric: 16.1754 - val_loss: 7556.6687 - val_evaluation_metric: 26.0792\n",
      "\n",
      "Epoch 00116: val_evaluation_metric improved from 25.93689 to 26.07923, saving model to ./lstm_raw.h5\n",
      "Epoch 117/2000\n",
      " - 11s - loss: 8406.1396 - evaluation_metric: 16.1560 - val_loss: 7519.2080 - val_evaluation_metric: 26.2236\n",
      "\n",
      "Epoch 00117: val_evaluation_metric improved from 26.07923 to 26.22358, saving model to ./lstm_raw.h5\n",
      "Epoch 118/2000\n",
      " - 10s - loss: 8371.6526 - evaluation_metric: 16.1474 - val_loss: 7480.8574 - val_evaluation_metric: 26.3780\n",
      "\n",
      "Epoch 00118: val_evaluation_metric improved from 26.22358 to 26.37803, saving model to ./lstm_raw.h5\n",
      "Epoch 119/2000\n",
      " - 10s - loss: 8334.0385 - evaluation_metric: 16.1266 - val_loss: 7442.9539 - val_evaluation_metric: 26.5373\n",
      "\n",
      "Epoch 00119: val_evaluation_metric improved from 26.37803 to 26.53728, saving model to ./lstm_raw.h5\n",
      "Epoch 120/2000\n",
      " - 11s - loss: 8299.1500 - evaluation_metric: 16.1455 - val_loss: 7404.8862 - val_evaluation_metric: 26.7038\n",
      "\n",
      "Epoch 00120: val_evaluation_metric improved from 26.53728 to 26.70380, saving model to ./lstm_raw.h5\n",
      "Epoch 121/2000\n",
      " - 11s - loss: 8262.1719 - evaluation_metric: 16.1441 - val_loss: 7369.2954 - val_evaluation_metric: 26.8654\n",
      "\n",
      "Epoch 00121: val_evaluation_metric improved from 26.70380 to 26.86544, saving model to ./lstm_raw.h5\n",
      "Epoch 122/2000\n",
      " - 9s - loss: 8229.5282 - evaluation_metric: 16.1600 - val_loss: 7333.2800 - val_evaluation_metric: 27.0348\n",
      "\n",
      "Epoch 00122: val_evaluation_metric improved from 26.86544 to 27.03484, saving model to ./lstm_raw.h5\n",
      "Epoch 123/2000\n",
      " - 7s - loss: 8195.2758 - evaluation_metric: 16.1885 - val_loss: 7299.6873 - val_evaluation_metric: 27.1981\n",
      "\n",
      "Epoch 00123: val_evaluation_metric improved from 27.03484 to 27.19814, saving model to ./lstm_raw.h5\n",
      "Epoch 124/2000\n",
      " - 7s - loss: 8163.0528 - evaluation_metric: 16.2113 - val_loss: 7265.3328 - val_evaluation_metric: 27.3704\n",
      "\n",
      "Epoch 00124: val_evaluation_metric improved from 27.19814 to 27.37040, saving model to ./lstm_raw.h5\n",
      "Epoch 125/2000\n",
      " - 7s - loss: 8129.9192 - evaluation_metric: 16.2475 - val_loss: 7230.7378 - val_evaluation_metric: 27.5492\n",
      "\n",
      "Epoch 00125: val_evaluation_metric improved from 27.37040 to 27.54924, saving model to ./lstm_raw.h5\n",
      "Epoch 126/2000\n",
      " - 7s - loss: 8097.0339 - evaluation_metric: 16.2546 - val_loss: 7196.3118 - val_evaluation_metric: 27.7326\n",
      "\n",
      "Epoch 00126: val_evaluation_metric improved from 27.54924 to 27.73258, saving model to ./lstm_raw.h5\n",
      "Epoch 127/2000\n",
      " - 7s - loss: 8063.7709 - evaluation_metric: 16.3093 - val_loss: 7162.0251 - val_evaluation_metric: 27.9205\n",
      "\n",
      "Epoch 00127: val_evaluation_metric improved from 27.73258 to 27.92049, saving model to ./lstm_raw.h5\n",
      "Epoch 128/2000\n",
      " - 7s - loss: 8031.7885 - evaluation_metric: 16.3692 - val_loss: 7126.2439 - val_evaluation_metric: 28.0943\n",
      "\n",
      "Epoch 00128: val_evaluation_metric improved from 27.92049 to 28.09431, saving model to ./lstm_raw.h5\n",
      "Epoch 129/2000\n",
      " - 7s - loss: 7998.8021 - evaluation_metric: 16.3324 - val_loss: 7091.0183 - val_evaluation_metric: 28.2074\n",
      "\n",
      "Epoch 00129: val_evaluation_metric improved from 28.09431 to 28.20738, saving model to ./lstm_raw.h5\n",
      "Epoch 130/2000\n",
      " - 7s - loss: 7965.2183 - evaluation_metric: 16.2872 - val_loss: 7058.0776 - val_evaluation_metric: 28.3194\n",
      "\n",
      "Epoch 00130: val_evaluation_metric improved from 28.20738 to 28.31936, saving model to ./lstm_raw.h5\n",
      "Epoch 131/2000\n",
      " - 8s - loss: 7933.5600 - evaluation_metric: 16.2482 - val_loss: 7025.4316 - val_evaluation_metric: 28.4371\n",
      "\n",
      "Epoch 00131: val_evaluation_metric improved from 28.31936 to 28.43705, saving model to ./lstm_raw.h5\n",
      "Epoch 132/2000\n",
      " - 6s - loss: 7902.1169 - evaluation_metric: 16.2143 - val_loss: 6991.9512 - val_evaluation_metric: 28.5647\n",
      "\n",
      "Epoch 00132: val_evaluation_metric improved from 28.43705 to 28.56467, saving model to ./lstm_raw.h5\n",
      "Epoch 133/2000\n",
      " - 8s - loss: 7869.0810 - evaluation_metric: 16.1799 - val_loss: 6958.5933 - val_evaluation_metric: 28.6987\n",
      "\n",
      "Epoch 00133: val_evaluation_metric improved from 28.56467 to 28.69872, saving model to ./lstm_raw.h5\n",
      "Epoch 134/2000\n",
      " - 8s - loss: 7837.9361 - evaluation_metric: 16.1558 - val_loss: 6923.2341 - val_evaluation_metric: 28.8483\n",
      "\n",
      "Epoch 00134: val_evaluation_metric improved from 28.69872 to 28.84831, saving model to ./lstm_raw.h5\n",
      "Epoch 135/2000\n",
      " - 7s - loss: 7804.0806 - evaluation_metric: 16.1273 - val_loss: 6888.3748 - val_evaluation_metric: 28.9985\n",
      "\n",
      "Epoch 00135: val_evaluation_metric improved from 28.84831 to 28.99852, saving model to ./lstm_raw.h5\n",
      "Epoch 136/2000\n",
      " - 8s - loss: 7770.3908 - evaluation_metric: 16.1305 - val_loss: 6853.9639 - val_evaluation_metric: 29.0652\n",
      "\n",
      "Epoch 00136: val_evaluation_metric improved from 28.99852 to 29.06521, saving model to ./lstm_raw.h5\n",
      "Epoch 137/2000\n",
      " - 9s - loss: 7738.6940 - evaluation_metric: 16.1052 - val_loss: 6818.4387 - val_evaluation_metric: 29.1412\n",
      "\n",
      "Epoch 00137: val_evaluation_metric improved from 29.06521 to 29.14115, saving model to ./lstm_raw.h5\n",
      "Epoch 138/2000\n",
      " - 9s - loss: 7705.0016 - evaluation_metric: 16.1487 - val_loss: 6784.9714 - val_evaluation_metric: 29.2219\n",
      "\n",
      "Epoch 00138: val_evaluation_metric improved from 29.14115 to 29.22185, saving model to ./lstm_raw.h5\n",
      "Epoch 139/2000\n",
      " - 8s - loss: 7673.3063 - evaluation_metric: 16.1347 - val_loss: 6751.6499 - val_evaluation_metric: 29.3109\n",
      "\n",
      "Epoch 00139: val_evaluation_metric improved from 29.22185 to 29.31095, saving model to ./lstm_raw.h5\n",
      "Epoch 140/2000\n",
      " - 7s - loss: 7642.0843 - evaluation_metric: 16.1361 - val_loss: 6718.8340 - val_evaluation_metric: 29.4071\n",
      "\n",
      "Epoch 00140: val_evaluation_metric improved from 29.31095 to 29.40713, saving model to ./lstm_raw.h5\n",
      "Epoch 141/2000\n",
      " - 9s - loss: 7609.9155 - evaluation_metric: 16.1611 - val_loss: 6686.9624 - val_evaluation_metric: 29.5085\n",
      "\n",
      "Epoch 00141: val_evaluation_metric improved from 29.40713 to 29.50849, saving model to ./lstm_raw.h5\n",
      "Epoch 142/2000\n",
      " - 10s - loss: 7580.8452 - evaluation_metric: 16.1873 - val_loss: 6654.4709 - val_evaluation_metric: 29.6195\n",
      "\n",
      "Epoch 00142: val_evaluation_metric improved from 29.50849 to 29.61953, saving model to ./lstm_raw.h5\n",
      "Epoch 143/2000\n",
      " - 10s - loss: 7550.5756 - evaluation_metric: 16.2248 - val_loss: 6622.9297 - val_evaluation_metric: 29.7338\n",
      "\n",
      "Epoch 00143: val_evaluation_metric improved from 29.61953 to 29.73380, saving model to ./lstm_raw.h5\n",
      "Epoch 144/2000\n",
      " - 9s - loss: 7520.7798 - evaluation_metric: 16.2760 - val_loss: 6591.3806 - val_evaluation_metric: 29.8556\n",
      "\n",
      "Epoch 00144: val_evaluation_metric improved from 29.73380 to 29.85563, saving model to ./lstm_raw.h5\n",
      "Epoch 145/2000\n",
      " - 11s - loss: 7491.7161 - evaluation_metric: 16.2775 - val_loss: 6559.5732 - val_evaluation_metric: 29.9860\n",
      "\n",
      "Epoch 00145: val_evaluation_metric improved from 29.85563 to 29.98603, saving model to ./lstm_raw.h5\n",
      "Epoch 146/2000\n",
      " - 12s - loss: 7461.3780 - evaluation_metric: 16.3483 - val_loss: 6528.7195 - val_evaluation_metric: 30.1053\n",
      "\n",
      "Epoch 00146: val_evaluation_metric improved from 29.98603 to 30.10533, saving model to ./lstm_raw.h5\n",
      "Epoch 147/2000\n",
      " - 11s - loss: 7432.0808 - evaluation_metric: 16.3333 - val_loss: 6498.6152 - val_evaluation_metric: 30.1580\n",
      "\n",
      "Epoch 00147: val_evaluation_metric improved from 30.10533 to 30.15800, saving model to ./lstm_raw.h5\n",
      "Epoch 148/2000\n",
      " - 13s - loss: 7402.5429 - evaluation_metric: 16.2974 - val_loss: 6468.6584 - val_evaluation_metric: 30.2176\n",
      "\n",
      "Epoch 00148: val_evaluation_metric improved from 30.15800 to 30.21765, saving model to ./lstm_raw.h5\n",
      "Epoch 149/2000\n",
      " - 14s - loss: 7374.0571 - evaluation_metric: 16.2403 - val_loss: 6437.9023 - val_evaluation_metric: 30.2877\n",
      "\n",
      "Epoch 00149: val_evaluation_metric improved from 30.21765 to 30.28766, saving model to ./lstm_raw.h5\n",
      "Epoch 150/2000\n",
      " - 12s - loss: 7345.3237 - evaluation_metric: 16.2035 - val_loss: 6407.1604 - val_evaluation_metric: 30.3664\n",
      "\n",
      "Epoch 00150: val_evaluation_metric improved from 30.28766 to 30.36642, saving model to ./lstm_raw.h5\n",
      "Epoch 151/2000\n",
      " - 10s - loss: 7316.2346 - evaluation_metric: 16.1771 - val_loss: 6377.3813 - val_evaluation_metric: 30.4510\n",
      "\n",
      "Epoch 00151: val_evaluation_metric improved from 30.36642 to 30.45102, saving model to ./lstm_raw.h5\n",
      "Epoch 152/2000\n",
      " - 10s - loss: 7287.8295 - evaluation_metric: 16.1699 - val_loss: 6347.8381 - val_evaluation_metric: 30.5429\n",
      "\n",
      "Epoch 00152: val_evaluation_metric improved from 30.45102 to 30.54294, saving model to ./lstm_raw.h5\n",
      "Epoch 153/2000\n",
      " - 10s - loss: 7260.9211 - evaluation_metric: 16.1490 - val_loss: 6318.0901 - val_evaluation_metric: 30.6435\n",
      "\n",
      "Epoch 00153: val_evaluation_metric improved from 30.54294 to 30.64349, saving model to ./lstm_raw.h5\n",
      "Epoch 154/2000\n",
      " - 10s - loss: 7232.7512 - evaluation_metric: 16.1359 - val_loss: 6288.9009 - val_evaluation_metric: 30.6979\n",
      "\n",
      "Epoch 00154: val_evaluation_metric improved from 30.64349 to 30.69786, saving model to ./lstm_raw.h5\n",
      "Epoch 155/2000\n",
      " - 10s - loss: 7204.6774 - evaluation_metric: 16.1112 - val_loss: 6259.3696 - val_evaluation_metric: 30.7261\n",
      "\n",
      "Epoch 00155: val_evaluation_metric improved from 30.69786 to 30.72605, saving model to ./lstm_raw.h5\n",
      "Epoch 156/2000\n",
      " - 11s - loss: 7177.0526 - evaluation_metric: 16.1206 - val_loss: 6230.3005 - val_evaluation_metric: 30.7626\n",
      "\n",
      "Epoch 00156: val_evaluation_metric improved from 30.72605 to 30.76256, saving model to ./lstm_raw.h5\n",
      "Epoch 157/2000\n",
      " - 10s - loss: 7149.1501 - evaluation_metric: 16.1333 - val_loss: 6201.4502 - val_evaluation_metric: 30.8080\n",
      "\n",
      "Epoch 00157: val_evaluation_metric improved from 30.76256 to 30.80797, saving model to ./lstm_raw.h5\n",
      "Epoch 158/2000\n",
      " - 10s - loss: 7121.8083 - evaluation_metric: 16.1310 - val_loss: 6173.6960 - val_evaluation_metric: 30.8602\n",
      "\n",
      "Epoch 00158: val_evaluation_metric improved from 30.80797 to 30.86018, saving model to ./lstm_raw.h5\n",
      "Epoch 159/2000\n",
      " - 10s - loss: 7095.9906 - evaluation_metric: 16.1525 - val_loss: 6144.8921 - val_evaluation_metric: 30.9231\n",
      "\n",
      "Epoch 00159: val_evaluation_metric improved from 30.86018 to 30.92310, saving model to ./lstm_raw.h5\n",
      "Epoch 160/2000\n",
      " - 11s - loss: 7068.7252 - evaluation_metric: 16.1681 - val_loss: 6116.5686 - val_evaluation_metric: 30.9936\n",
      "\n",
      "Epoch 00160: val_evaluation_metric improved from 30.92310 to 30.99360, saving model to ./lstm_raw.h5\n",
      "Epoch 161/2000\n",
      " - 10s - loss: 7042.4884 - evaluation_metric: 16.1865 - val_loss: 6089.4414 - val_evaluation_metric: 31.0684\n",
      "\n",
      "Epoch 00161: val_evaluation_metric improved from 30.99360 to 31.06840, saving model to ./lstm_raw.h5\n",
      "Epoch 162/2000\n",
      " - 50s - loss: 7016.5336 - evaluation_metric: 16.2233 - val_loss: 6062.3521 - val_evaluation_metric: 31.1496\n",
      "\n",
      "Epoch 00162: val_evaluation_metric improved from 31.06840 to 31.14960, saving model to ./lstm_raw.h5\n",
      "Epoch 163/2000\n",
      " - 26s - loss: 6991.8505 - evaluation_metric: 16.2400 - val_loss: 6034.1003 - val_evaluation_metric: 31.2417\n",
      "\n",
      "Epoch 00163: val_evaluation_metric improved from 31.14960 to 31.24174, saving model to ./lstm_raw.h5\n",
      "Epoch 164/2000\n",
      " - 12s - loss: 6966.3114 - evaluation_metric: 16.2819 - val_loss: 6006.7219 - val_evaluation_metric: 31.3389\n",
      "\n",
      "Epoch 00164: val_evaluation_metric improved from 31.24174 to 31.33894, saving model to ./lstm_raw.h5\n",
      "Epoch 165/2000\n",
      " - 11s - loss: 6940.1978 - evaluation_metric: 16.3063 - val_loss: 5980.3237 - val_evaluation_metric: 31.4400\n",
      "\n",
      "Epoch 00165: val_evaluation_metric improved from 31.33894 to 31.43996, saving model to ./lstm_raw.h5\n",
      "Epoch 166/2000\n",
      " - 9s - loss: 6914.8993 - evaluation_metric: 16.3426 - val_loss: 5954.3259 - val_evaluation_metric: 31.4666\n",
      "\n",
      "Epoch 00166: val_evaluation_metric improved from 31.43996 to 31.46660, saving model to ./lstm_raw.h5\n",
      "Epoch 167/2000\n",
      " - 10s - loss: 6890.2003 - evaluation_metric: 16.2692 - val_loss: 5928.2095 - val_evaluation_metric: 31.5005\n",
      "\n",
      "Epoch 00167: val_evaluation_metric improved from 31.46660 to 31.50051, saving model to ./lstm_raw.h5\n",
      "Epoch 168/2000\n",
      " - 10s - loss: 6866.2279 - evaluation_metric: 16.2294 - val_loss: 5902.1470 - val_evaluation_metric: 31.5426\n",
      "\n",
      "Epoch 00168: val_evaluation_metric improved from 31.50051 to 31.54259, saving model to ./lstm_raw.h5\n",
      "Epoch 169/2000\n",
      " - 7s - loss: 6840.5692 - evaluation_metric: 16.2092 - val_loss: 5876.0127 - val_evaluation_metric: 31.5933\n",
      "\n",
      "Epoch 00169: val_evaluation_metric improved from 31.54259 to 31.59325, saving model to ./lstm_raw.h5\n",
      "Epoch 170/2000\n",
      " - 7s - loss: 6815.9140 - evaluation_metric: 16.1829 - val_loss: 5849.4792 - val_evaluation_metric: 31.6533\n",
      "\n",
      "Epoch 00170: val_evaluation_metric improved from 31.59325 to 31.65328, saving model to ./lstm_raw.h5\n",
      "Epoch 171/2000\n",
      " - 7s - loss: 6792.2560 - evaluation_metric: 16.1348 - val_loss: 5822.8943 - val_evaluation_metric: 31.7220\n",
      "\n",
      "Epoch 00171: val_evaluation_metric improved from 31.65328 to 31.72203, saving model to ./lstm_raw.h5\n",
      "Epoch 172/2000\n",
      " - 7s - loss: 6766.1538 - evaluation_metric: 16.1305 - val_loss: 5797.1851 - val_evaluation_metric: 31.7966\n",
      "\n",
      "Epoch 00172: val_evaluation_metric improved from 31.72203 to 31.79663, saving model to ./lstm_raw.h5\n",
      "Epoch 173/2000\n",
      " - 6s - loss: 6742.6940 - evaluation_metric: 16.1235 - val_loss: 5771.5791 - val_evaluation_metric: 31.8751\n",
      "\n",
      "Epoch 00173: val_evaluation_metric improved from 31.79663 to 31.87506, saving model to ./lstm_raw.h5\n",
      "Epoch 174/2000\n",
      " - 6s - loss: 6719.0731 - evaluation_metric: 16.1144 - val_loss: 5746.3301 - val_evaluation_metric: 31.8829\n",
      "\n",
      "Epoch 00174: val_evaluation_metric improved from 31.87506 to 31.88287, saving model to ./lstm_raw.h5\n",
      "Epoch 175/2000\n",
      " - 7s - loss: 6694.2894 - evaluation_metric: 16.0980 - val_loss: 5722.0186 - val_evaluation_metric: 31.8968\n",
      "\n",
      "Epoch 00175: val_evaluation_metric improved from 31.88287 to 31.89678, saving model to ./lstm_raw.h5\n",
      "Epoch 176/2000\n",
      " - 7s - loss: 6673.5630 - evaluation_metric: 16.1015 - val_loss: 5697.3372 - val_evaluation_metric: 31.9193\n",
      "\n",
      "Epoch 00176: val_evaluation_metric improved from 31.89678 to 31.91934, saving model to ./lstm_raw.h5\n",
      "Epoch 177/2000\n",
      " - 7s - loss: 6650.2250 - evaluation_metric: 16.1168 - val_loss: 5674.2153 - val_evaluation_metric: 31.9483\n",
      "\n",
      "Epoch 00177: val_evaluation_metric improved from 31.91934 to 31.94834, saving model to ./lstm_raw.h5\n",
      "Epoch 178/2000\n",
      " - 7s - loss: 6628.0464 - evaluation_metric: 16.1348 - val_loss: 5652.0483 - val_evaluation_metric: 31.9832\n",
      "\n",
      "Epoch 00178: val_evaluation_metric improved from 31.94834 to 31.98323, saving model to ./lstm_raw.h5\n",
      "Epoch 179/2000\n",
      " - 7s - loss: 6606.3192 - evaluation_metric: 16.1453 - val_loss: 5628.6492 - val_evaluation_metric: 32.0275\n",
      "\n",
      "Epoch 00179: val_evaluation_metric improved from 31.98323 to 32.02752, saving model to ./lstm_raw.h5\n",
      "Epoch 180/2000\n",
      " - 7s - loss: 6583.6066 - evaluation_metric: 16.1316 - val_loss: 5604.3877 - val_evaluation_metric: 32.0815\n",
      "\n",
      "Epoch 00180: val_evaluation_metric improved from 32.02752 to 32.08146, saving model to ./lstm_raw.h5\n",
      "Epoch 181/2000\n",
      " - 7s - loss: 6562.9118 - evaluation_metric: 16.1539 - val_loss: 5579.3455 - val_evaluation_metric: 32.1457\n",
      "\n",
      "Epoch 00181: val_evaluation_metric improved from 32.08146 to 32.14565, saving model to ./lstm_raw.h5\n",
      "Epoch 182/2000\n",
      " - 7s - loss: 6538.8006 - evaluation_metric: 16.1823 - val_loss: 5556.4863 - val_evaluation_metric: 32.2117\n",
      "\n",
      "Epoch 00182: val_evaluation_metric improved from 32.14565 to 32.21173, saving model to ./lstm_raw.h5\n",
      "Epoch 183/2000\n",
      " - 8s - loss: 6517.6880 - evaluation_metric: 16.2226 - val_loss: 5532.3762 - val_evaluation_metric: 32.2883\n",
      "\n",
      "Epoch 00183: val_evaluation_metric improved from 32.21173 to 32.28834, saving model to ./lstm_raw.h5\n",
      "Epoch 184/2000\n",
      " - 7s - loss: 6493.8373 - evaluation_metric: 16.2503 - val_loss: 5507.9846 - val_evaluation_metric: 32.3732\n",
      "\n",
      "Epoch 00184: val_evaluation_metric improved from 32.28834 to 32.37324, saving model to ./lstm_raw.h5\n",
      "Epoch 185/2000\n",
      " - 7s - loss: 6470.7747 - evaluation_metric: 16.2985 - val_loss: 5483.7585 - val_evaluation_metric: 32.4655\n",
      "\n",
      "Epoch 00185: val_evaluation_metric improved from 32.37324 to 32.46548, saving model to ./lstm_raw.h5\n",
      "Epoch 186/2000\n",
      " - 8s - loss: 6448.9649 - evaluation_metric: 16.3202 - val_loss: 5459.7809 - val_evaluation_metric: 32.5083\n",
      "\n",
      "Epoch 00186: val_evaluation_metric improved from 32.46548 to 32.50832, saving model to ./lstm_raw.h5\n",
      "Epoch 187/2000\n",
      " - 8s - loss: 6426.8890 - evaluation_metric: 16.2756 - val_loss: 5436.4625 - val_evaluation_metric: 32.5330\n",
      "\n",
      "Epoch 00187: val_evaluation_metric improved from 32.50832 to 32.53298, saving model to ./lstm_raw.h5\n",
      "Epoch 188/2000\n",
      " - 8s - loss: 6405.7586 - evaluation_metric: 16.2540 - val_loss: 5414.0042 - val_evaluation_metric: 32.5634\n",
      "\n",
      "Epoch 00188: val_evaluation_metric improved from 32.53298 to 32.56342, saving model to ./lstm_raw.h5\n",
      "Epoch 189/2000\n",
      " - 9s - loss: 6383.8113 - evaluation_metric: 16.2033 - val_loss: 5391.7318 - val_evaluation_metric: 32.6016\n",
      "\n",
      "Epoch 00189: val_evaluation_metric improved from 32.56342 to 32.60160, saving model to ./lstm_raw.h5\n",
      "Epoch 190/2000\n",
      " - 10s - loss: 6363.2188 - evaluation_metric: 16.1738 - val_loss: 5369.8296 - val_evaluation_metric: 32.6064\n",
      "\n",
      "Epoch 00190: val_evaluation_metric improved from 32.60160 to 32.60642, saving model to ./lstm_raw.h5\n",
      "Epoch 191/2000\n",
      " - 9s - loss: 6343.3214 - evaluation_metric: 16.1444 - val_loss: 5349.1482 - val_evaluation_metric: 32.5848\n",
      "\n",
      "Epoch 00191: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 192/2000\n",
      " - 9s - loss: 6324.3425 - evaluation_metric: 16.1354 - val_loss: 5328.0891 - val_evaluation_metric: 32.5699\n",
      "\n",
      "Epoch 00192: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 193/2000\n",
      " - 10s - loss: 6303.9461 - evaluation_metric: 16.1057 - val_loss: 5307.1426 - val_evaluation_metric: 32.5631\n",
      "\n",
      "Epoch 00193: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 194/2000\n",
      " - 9s - loss: 6285.3622 - evaluation_metric: 16.0857 - val_loss: 5285.8538 - val_evaluation_metric: 32.5548\n",
      "\n",
      "Epoch 00194: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 195/2000\n",
      " - 10s - loss: 6265.9537 - evaluation_metric: 16.0877 - val_loss: 5265.1344 - val_evaluation_metric: 32.4908\n",
      "\n",
      "Epoch 00195: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 196/2000\n",
      " - 9s - loss: 6245.5060 - evaluation_metric: 16.0807 - val_loss: 5245.1951 - val_evaluation_metric: 32.4365\n",
      "\n",
      "Epoch 00196: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 197/2000\n",
      " - 10s - loss: 6227.1278 - evaluation_metric: 16.1043 - val_loss: 5224.0874 - val_evaluation_metric: 32.3868\n",
      "\n",
      "Epoch 00197: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 198/2000\n",
      " - 10s - loss: 6207.4930 - evaluation_metric: 16.0961 - val_loss: 5203.5648 - val_evaluation_metric: 32.3474\n",
      "\n",
      "Epoch 00198: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 199/2000\n",
      " - 9s - loss: 6188.3090 - evaluation_metric: 16.0967 - val_loss: 5183.0298 - val_evaluation_metric: 32.3158\n",
      "\n",
      "Epoch 00199: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 200/2000\n",
      " - 10s - loss: 6169.1448 - evaluation_metric: 16.1215 - val_loss: 5162.6006 - val_evaluation_metric: 32.2927\n",
      "\n",
      "Epoch 00200: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 201/2000\n",
      " - 11s - loss: 6149.3596 - evaluation_metric: 16.1392 - val_loss: 5142.7391 - val_evaluation_metric: 32.2774\n",
      "\n",
      "Epoch 00201: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 202/2000\n",
      " - 10s - loss: 6131.2234 - evaluation_metric: 16.1382 - val_loss: 5122.0215 - val_evaluation_metric: 32.2697\n",
      "\n",
      "Epoch 00202: val_evaluation_metric did not improve from 32.60642\n",
      "Epoch 203/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3b0684971646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluation_metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/shuzhilian/anaconda3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/shuzhilian/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shuzhilian/anaconda3/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shuzhilian/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shuzhilian/anaconda3/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"./lstm_raw.h5\",monitor='val_evaluation_metric',verbose=1,save_best_only='True',\n",
    "                             mode='max',period=1)\n",
    "# tensorboard = TensorBoard(log_dir='log(./)')\n",
    "callback_lists = [checkpoint]  #因为callback是list型,必须转化为list\n",
    "graph = tf.get_default_graph()\n",
    "model=LSTM_model((60,25600))\n",
    "model.summary()\n",
    "Adam = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam,metrics=[evaluation_metric])\n",
    "# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\n",
    "model.fit(train_data,train_label, epochs=2000, verbose=2,batch_size=25,validation_data=(valid_data, valid_label),callbacks=callback_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('lstm_raw_fft.h5',{\"evaluation_metric\":evaluation_metric})\n",
    "model = load_model('lstm_raw.h5',{\"evaluation_metric\":evaluation_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicted=model.predict(train_fft_data).reshape(-1,)\n",
    "predicted=model.predict(train_data).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.150156789537\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1dad793be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result=pd.DataFrame({\"real\":train_label.reshape(-1,),\"predicted\":predicted})\n",
    "df_predict=df_result[\"predicted\"].groupby(df_result['real']).mean()\n",
    "err=Error_compute(df_predict.index,df_predict)\n",
    "print(err)\n",
    "plt_plot(df_predict.index,df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.326715789601\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKmZwkCRJFTM4SJKkiv0/SANTILDLBugAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d568bcf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted=model.predict(valid_data).reshape(-1,)\n",
    "df_result=pd.DataFrame({\"real\":valid_label.reshape(-1,),\"predicted\":predicted})\n",
    "df_predict=df_result[\"predicted\"].groupby(df_result['real']).mean()\n",
    "err=Error_compute(df_predict.index,df_predict)\n",
    "print(err)\n",
    "plt_plot(df_predict.index,df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=data_generator(train_data_list_pool,label_data_list_pool,source_dire_list,batch_size=5,time_range=1)\n",
    "i=1\n",
    "for data ,label in a:\n",
    "    print(data.shape,label.shape)\n",
    "    print(i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration.values,60\n",
    "def get_train_data_list_pool(data_dire_list):#获得多个文件夹中的源数据\n",
    "    train_data_list_pool=[]\n",
    "    label_data_list_pool=[]# source data from mutiply floder \n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        train_data_pool_list=[]\n",
    "        label_data_pool_list=[]\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_list=[]\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "            label_data_pool_list.append(residual_life_list)\n",
    "            train_data_pool_list.append(df_60s)\n",
    "        train_data_list_pool.append(train_data_pool_list)\n",
    "        label_data_list_pool.append(label_data_pool_list)\n",
    "    return train_data_list_pool,label_data_list_pool\n",
    "\n",
    "def data_generator(train_data_list_pool,label_data_list_pool,data_dire_list,batch_size=5,time_range=1):\n",
    "#     train_data_list_pool,label_data_list_pool=get_train_data_list_pool(data_dire_list)\n",
    "    \n",
    "    file_list_length=0#获得一个epoch中每个batch需要输出的所有随机样本序列号\n",
    "    for train_data_list in train_data_list_pool:\n",
    "        file_list_length=file_list_length+len(train_data_list)-time_range\n",
    "    batch_random_list_epoch=list(range(1,(file_list_length+1)))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    exit()\n",
    "    for i in range((file_list_length)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "#         label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]#某batch需要输出的样本序列号\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            \n",
    "            upper_bound_file_num=0                               #确定从第几个文件夹中获取数据\n",
    "            lower_bound_file_num=0\n",
    "            for floder_index in range(len(train_data_list_pool)):\n",
    "                upper_bound_file_num=upper_bound_file_num+len(train_data_list_pool[floder_index])-time_range\n",
    "                if start_index<=upper_bound_file_num:\n",
    "                    for minute_index in range(start_index,start_index+time_range):#将time_range分钟的数据连接在一起\n",
    "#                         print(\"floder_index,file_index\",floder_index,minute_index-lower_bound_file_num)\n",
    "                        df_60s=train_data_list_pool[floder_index][minute_index-1-lower_bound_file_num]\n",
    "                        reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                        signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                        residual_life_list.extend(label_data_list_pool[floder_index][minute_index-1-lower_bound_file_num])\n",
    "                    break\n",
    "                lower_bound_file_num=lower_bound_file_num+len(train_data_list_pool[floder_index])-time_range\n",
    "                \n",
    "            resudual_life_array = np.array(residual_life_list)#把上一步中得到的time_range分钟数据作为一条样本加到一个batch组中\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "            label_data=label_data.reshape(-1,60,)\n",
    "            gc.collect()\n",
    "            yield train_data,label_data\n",
    "#         for data,label in zip(train_data,label_data):\n",
    "#             yield data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(range(len(df_signal[\"vibration_1\"])),df_signal[\"vibration_1\"], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dire=os.path.join(source_dire,'0'+str(1),'Sensor')\n",
    "file_list_length=len(os.listdir(file_dire))\n",
    "for file_index in range(1,file_list_length+1):\n",
    "    df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "    print(file_index,df_signal.shape)\n",
    "\n",
    "df_signal=pd.read_csv(os.path.join(file_dire,str(13)+\".csv\"))\n",
    "if df_signal.shape[0]<1536000:\n",
    "    zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "    df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "df_signal=df_signal.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_data_generator(data_dire,batch_size=5,time_range=1,dire_index=1):\n",
    "    file_dire=os.path.join(data_dire,'0'+str(dire_index),'Sensor')\n",
    "    file_list_length=len(os.listdir(file_dire))\n",
    "    batch_random_list_epoch=list(range(1,file_list_length+1-time_range))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    for i in range((file_list_length+1-time_range)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            for file_index in range(start_index,start_index+time_range):\n",
    "                df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "                df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "                reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "            resudual_life_array = np.array(residual_life_list)\n",
    "            gc.collect()\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "        yield train_data,label_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "def get_train_data_pool(data_dire,dire_index=1):\n",
    "    file_dire=os.path.join(data_dire,'0'+str(dire_index),'Sensor')\n",
    "    file_list_length=len(os.listdir(file_dire))\n",
    "    train_data_pool_list=[]\n",
    "    label_data_pool_list=[]\n",
    "    for file_index in range(1,file_list_length+1):\n",
    "        residual_life_list=[]\n",
    "        df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "        df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "        residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "        label_data_pool_list.append(residual_life_list)\n",
    "        train_data_pool_list.append(df_60s)\n",
    "    return train_data_pool_list,label_data_pool_list    \n",
    "def sequence_data_generator_load_memary(data_dire,batch_size=5,time_range=1,dire_index=1):\n",
    "    train_data_pool_list,label_data_pool_list=get_train_data_pool(data_dire)\n",
    "    file_list_length=len(train_data_pool_list)\n",
    "    batch_random_list_epoch=list(range(1,file_list_length+1-time_range))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    for i in range((file_list_length+1-time_range)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            for file_index in range(start_index,start_index+time_range):\n",
    "                df_60s=train_data_pool_list[file_index-1]\n",
    "                reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                residual_life_list.extend(label_data_pool_list[file_index-1])\n",
    "            resudual_life_array = np.array(residual_life_list)\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "            gc.collect()\n",
    "        yield train_data,label_data     "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
