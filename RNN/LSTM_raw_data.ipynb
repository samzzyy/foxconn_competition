{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.fftpack import fft,ifft\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_plot(y_real,y_predict):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(range(len(y_real)),y_real, color='r')\n",
    "    ax.plot(range(len(y_predict)),y_predict, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "\n",
    "def load_train_fft_data(data_dire_list,sensor_channel=\"vibration_1\"):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,12800)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    window=25600\n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            fft_train_data_60s=np.array([]).reshape(-1,12800)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5]*seconds_counts).reshape(-1,60,1),axis=0)\n",
    "            for _ in range(60):\n",
    "                freqs=np.fft.fft(df_60s[sensor_channel][window*_:window*(_+1)])\n",
    "                freqs=freqs[0:12800].reshape(-1,12800)\n",
    "                fft_train_data_60s=np.append(fft_train_data_60s,freqs)\n",
    "            train_data_pool_array=np.append(train_data_pool_array,fft_train_data_60s.reshape(-1,60,12800),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "\n",
    "    label_filename = os.path.join(mkdtemp(), 'label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data\n",
    "def load_test_fft_data(data_dire_list,tool_age_list,sensor_channel=\"vibration_1\"):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,12800)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    window=12800\n",
    "    for data_dire,index in zip(data_dire_list,range(len(data_dire_list))):\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            fft_train_data_60s=np.array([]).reshape(-1,12800)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5+tool_age_list[index]]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "#             print(data_dire,str(file_index)+'.csv',(file_list_length-file_index)*5+tool_age_list[index])\n",
    "            for _ in range(60):\n",
    "                freqs=np.fft.fft(df_60s[sensor_channel][window*_:window*(_+1)])\n",
    "                freqs=abs(freqs[0:12800].reshape(-1,12800))\n",
    "                fft_train_data_60s=np.append(fft_train_data_60s,freqs)\n",
    "            train_data_pool_array=np.append(train_data_pool_array,fft_train_data_60s.reshape(-1,60,12800),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'test_source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'test_label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "def load_train_data(data_dire_list):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,25600)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "            train_data_pool_array=np.append(train_data_pool_array,df_60s['vibration_1'].values.reshape(-1,60,25600),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data\n",
    "def load_test_data(data_dire_list,tool_age_list):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,25600)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    for data_dire,index in zip(data_dire_list,range(len(data_dire_list))):\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5+tool_age_list[index]]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "            train_data_pool_array=np.append(train_data_pool_array,df_60s['vibration_1'].values.reshape(-1,60,25600),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'test_source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'test_label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dire = \"../../01-TrainingData-additional/\"\n",
    "source_dire_list=[\n",
    "    \"../../01-TrainingData-additional/01/\",\n",
    "    \"../../01-TrainingData-additional/02/\",\n",
    "  \"../../01-TrainingData-additional/03/\"\n",
    "]\n",
    "test_dire = \"../../02-TestingData-keD1/\"\n",
    "test_dire_list=[\n",
    "    \"../../02-TestingData-keD1/01/\",\n",
    "    \"../../02-TestingData-keD1/02/\",\n",
    "  \"../../02-TestingData-keD1/03/\",\n",
    "    \"../../02-TestingData-keD1/04/\",\n",
    "    \"../../02-TestingData-keD1/05/\"\n",
    "]\n",
    "tool_age_list=[104,52,190,66,40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4181"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,train_label=load_train_data(source_dire_list)\n",
    "valid_data,valid_label=load_test_data(test_dire_list,tool_age_list)\n",
    "\n",
    "# train_fft_data,train_label=load_train_fft_data(source_dire_list)\n",
    "# valid_fft_data,valid_label=load_test_fft_data(test_dire_list,tool_age_list)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras import models as M\n",
    "from keras import layers as L\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(y_true, y_pred):\n",
    "    y_true, y_pred = tf.reshape(y_true, [-1]), tf.reshape(y_pred, [-1])\n",
    "    er = y_true - y_pred\n",
    "    mask_n, mask_p = (er<=0), (er>0)\n",
    "    er_n, er_p = tf.boolean_mask(er, mask_n), tf.boolean_mask(er, mask_p)\n",
    "    score_n = tf.exp(-tf.log(0.5)*er_n/5)\n",
    "    score_p = tf.exp(tf.log(0.5)*er_p/20)\n",
    "    score = tf.concat([score_n, score_p], 0)\n",
    "    score = tf.reduce_mean(score)*100\n",
    "    return score\n",
    "def cust_loss1(y_real,y_predicted):\n",
    "    y_diff = y_real - y_predicted\n",
    "    loss = tf.where(tf.greater(y_diff, 0),\n",
    "                    -tf.exp(tf.log(0.5) * (y_diff / 20)) +1,\n",
    "                    -tf.exp(-tf.log(0.5) * (y_diff / 5)) +1)\n",
    "    return loss*tf.reduce_max(abs(y_diff))\n",
    "def cust_loss2(y_real,y_predicted):\n",
    "    y_diff = y_real - y_predicted\n",
    "    loss = tf.where(tf.greater(y_diff, 0),\n",
    "                    -tf.log(0.5) * (y_diff / 20),\n",
    "                    tf.log(0.5) * (y_diff / 5))\n",
    "    return loss**2\n",
    "def Error_compute(y_real,y_predicted):\n",
    "    y_diff=y_real-y_predicted\n",
    "    diff_positive=y_diff[y_diff>0]\n",
    "    diff_negitive_0=y_diff[y_diff<=0]\n",
    "    if diff_negitive_0.shape[0] >0:\n",
    "        sum_negitive_error=sum(np.exp(-np.log(0.5)*(diff_negitive_0/5)))\n",
    "    else:\n",
    "        sum_negitive_error=0\n",
    "    if diff_positive.shape[0] >0:\n",
    "        sum_positive_error=sum(np.exp(np.log(0.5)*(diff_positive/20)))\n",
    "    else:\n",
    "        sum_positive_error=0\n",
    "    return (sum_negitive_error+sum_positive_error)/len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "graph = None\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape):\n",
    "    x_input = L.Input(shape=input_shape)\n",
    "    x=L.LSTM(units=300,activation=\"tanh\",return_sequences=True)(x_input)#320\n",
    "    x=L.TimeDistributed(L.Dense(150))(x)\n",
    "    x=L.Dropout(0.5)(x)\n",
    "    x=L.LSTM(units=60,activation=\"tanh\",return_sequences=True)(x)\n",
    "    y=L.TimeDistributed(L.Dense(1))(x)\n",
    "    \n",
    "    model = M.Model(inputs=x_input, outputs=y, name=\"LSTM\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 12800)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 300)           15721200  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 5)             1505      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 5)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 60)            15840     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 15,738,606\n",
      "Trainable params: 15,738,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"./lstm_raw_fft.h5\",monitor='val_evaluation_metric',verbose=1,save_best_only='True',\n",
    "                             mode='max',period=1)\n",
    "# tensorboard = TensorBoard(log_dir='log(./)')\n",
    "callback_lists = [checkpoint]  #因为callback是list型,必须转化为list\n",
    "graph = tf.get_default_graph()\n",
    "model=LSTM_model((60,12800))\n",
    "model.summary()\n",
    "# model=LSTM_model((60,12800))\n",
    "Adam = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam,metrics=[evaluation_metric])\n",
    "# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\n",
    "model.fit(train_fft_data,train_label, epochs=1000, verbose=2,batch_size=25,\n",
    "          validation_data=(valid_fft_data, valid_label),callbacks=callback_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 25600)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 300)           31081200  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 150)           45150     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 60)            50640     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 31,177,051\n",
      "Trainable params: 31,177,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 133 samples, validate on 50 samples\n",
      "Epoch 1/2000\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"./lstm_raw.h5\",monitor='val_evaluation_metric',verbose=1,save_best_only='True',\n",
    "                             mode='max',period=1)\n",
    "# tensorboard = TensorBoard(log_dir='log(./)')\n",
    "callback_lists = [checkpoint]  #因为callback是list型,必须转化为list\n",
    "graph = tf.get_default_graph()\n",
    "model=LSTM_model((60,25600))\n",
    "model.summary()\n",
    "Adam = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam,metrics=[evaluation_metric])\n",
    "# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\n",
    "model.fit(train_data,train_label, epochs=2000, verbose=2,batch_size=25,validation_data=(valid_data, valid_label),callbacks=callback_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('lstm_raw_fft.h5',{\"evaluation_metric\":evaluation_metric})\n",
    "model = load_model('lstm_raw.h5',{\"evaluation_metric\":evaluation_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicted=model.predict(train_fft_data).reshape(-1,)\n",
    "predicted=model.predict(train_data).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.150347765327\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAHOlJREFUeJzt3X2MXeV94PHvDwgkkLVRYbFhKQ5ZGmciN2Q9LIRNILRY\ntRO0kDarLLNJUYCAUAhiR6JlsxsVFqSukmwwJQEViygNohmLEiHSKDBDaUJDeNN6SFuKIQqFkkDs\n8GJfW1Be/ewf517l+DIz3Jdz7r3n3O9HumJ8zvGd4yMnfuZ7nueeSCkhSZLUiX2GfQKSJKk6HDhI\nkqSOOXCQJEkdc+AgSZI65sBBkiR1zIGDJEnqmAMHSZLUMQcOkiSpYw4cJElSxxw4SJKkjnU1cIiI\nL0TEgxGxKyK2R8StEfGetmO+GRF72l7fbzvmgIi4NiKei4jdEXFLRBxWxB9IkiSVp9vicBLwNeAE\nYB3wNmAuIt7RdtztwApgZfM11bb/auA04BPAycARwHe6PBdJkjRg0c9DriLiUOBXwMkppXua274J\nLE8p/cEiv2cZ8CxwZkrp1ua21cBW4IMppQd7PiFJklSqfuc4HAwk4IW27ac0b2U8GhHXRcRv5PZN\nAvsBd7U2pJQeA54CTuzzfCRJUon26/U3RkSQ3XK4J6X0SG7X7WS3HZ4A/j3wf4DvR8SJKcsbK4FX\nU0q72t5ye3PfQt/rEGA98CTwcq/nLEnSGHo78C5gNqX0fL9v1vPAAbgOeB/wofzGlNLNuV/+U0T8\nI/A4cArwgx6/13rgL3v8vZIkCT4FfLvfN+lp4BARXwc+BpyUUvrlUsemlJ6IiOeAY8gGDtuA/SNi\nWVt1WNHct5AnAW666SYmJiZ6OWX1YHp6mo0bNw77NMaK13zwvOaD5zUfrK1bt/LpT38amv+W9qvr\ngUNz0HAG8JGU0lMdHH8kcAjQGmBsAV4HTgXykyOPAu5b5G1eBpiYmGDt2rXdnrJ6tHz5cq/3gHnN\nB89rPnhe86Ep5FZ/VwOHiLiObGnl6cCLEbGiuauRUno5Ig4CLiOb47CNrDJ8CfgpMAuQUtoVEd8A\nroqIHcBu4Brgx66okCRptHVbHC4gW0Xxw7btZwM3Am8A7wfOIltx8QzZgOFPUkqv5Y6fbh57C3AA\ncAdwYZfnIkmSBqyrgUNKacnlmymll4ENHbzPK8BFzZckSaoIn1WhRU1NtX/gp8rmNR88r/ngec2r\nra9PjhyUiFgLbNmyZYsTaiRJ6sL8/DyTk5MAkyml+X7fz+IgSZI65sBBkiR1zIGDJEnqmAMHSZLU\nMQcOkiSpYw4cJElSxxw4SJKkjjlwkCRJHXPgIEmSOubAQZIkdcyBgyRJgzQ7C3/4h7Bnz7DPpCcO\nHCRJGoRGA847DzZsgG3bYPfuYZ9RTxw4SJJUttlZWLMGNm+G66+HuTlYvnzYZ9UTBw6SJJUlXxne\n+154+GE4/3yIGPaZ9Wy/YZ+AJEm1NDsLn/0s7NyZVYbzzqv0gKHF4iBJUpFqWBnyLA6SJBVlbg7O\nPbd2lSHP4iBJUr9alWH9+lpWhjyLgyRJ/ajpXIbFWBwkSepFzecyLMbiIElSt8asMuRZHCRJ6tSY\nVoY8i4MkSZ0YgxUTnbA4SJK0lDFaMdEJi4MkSYsZ47kMi7E4SJLUzrkMi7I4SJKUZ2VYksVBkiSw\nMnTI4iBJkpWhYxYHSdL4sjJ0zeIgSRpPVoaeWBwkSePFytAXi4MkaXxYGfpmcZAk1Z+VoTAWB0lS\nvVkZCmVxkCTVk5WhFBYHSVL9tCpDo2FlKJjFQZJUH41GNmDYsAEmJqwMJbA4SJLqIV8ZNm3KvnbA\nUDiLgySp2haqDN6aKI3FQZJUXVaGgbM4SJKqx8owNBYHSVK1uGJiqCwOkqRqcMXESLA4SJJGn3MZ\nRobFQZI0uvKf/uhchpFgcZAkjSYrw0iyOEiSRouVYaRZHCRJo8MnWY68ropDRHwhIh6MiF0RsT0i\nbo2I9yxw3BUR8UxEvBQRd0bEMW37D4iIayPiuYjYHRG3RMRh/f5hJEkV5ZMsK6PbWxUnAV8DTgDW\nAW8D5iLiHa0DIuJS4PPA+cDxwIvAbETsn3ufq4HTgE8AJwNHAN/p8c8gSaqy2VlYswY2b84qw9wc\nrFo17LPSIrq6VZFS+lj+1xHxGeBXwCRwT3PzxcCVKaXvNY85C9gOfBy4OSKWAecAZ6aU7m4eczaw\nNSKOTyk92PsfR5JUGY0GXHIJ3HADrFuX/dcBw8jrd3LkwUACXgCIiKOBlcBdrQNSSruAB4ATm5uO\nIxuw5I95DHgqd4wkqc6sDJXV88AhIoLslsM9KaVHmptXkg0ktrcdvr25D2AF8GpzQLHYMZKkOtq1\ny7kMFdfPqorrgPcBHyroXN7S9PQ0y5cv32vb1NQUU1NTgzoFSVKvXDFRupmZGWZmZvba1mg0Cv0e\nPQ0cIuLrwMeAk1JKv8zt2gYEWVXIV4cVwEO5Y/aPiGVt1WFFc9+iNm7cyNq1a3s5ZUnSsDiXYWAW\n+mF6fn6eycnJwr5H17cqmoOGM4DfSSk9ld+XUnqC7B//U3PHLyNbhXFvc9MW4PW2Y1YDRwH3dXs+\nkqQR5lyG2umqOETEdcAUcDrwYkSsaO5qpJRebn59NfDFiPgZ8CRwJfAL4DbIJktGxDeAqyJiB7Ab\nuAb4sSsqJKkmrAy11e2tigvIJj/+sG372cCNACmlL0fEgcD1ZKsufgR8NKX0au74aeAN4BbgAOAO\n4MJuT16SNIKcy1Br3X6OQ0e3NlJKlwOXL7H/FeCi5kuSVAdWhrHgsyokSf2bnc3Kwo4dVoaa8+mY\nkqTe5Z8xsXq1n8swBiwOkqTeOJdhLFkcJEnd8UmWY83iIEnqnJVh7FkcJElvzcqgJouDJGlprphQ\njsVBkrSwRiO7LeGKCeVYHCRJb9aay9BowKZN2dcOGITFQZKUl68MExNZZfDWhHIsDpKkjJVBHbA4\nSNK4szKoCxYHSRpnVgZ1yeIgSeMoXxlan8tgZVAHLA6SNG6sDOqDxUGSxoVzGVQAi4MkjQMrgwpi\ncZCkOss/Y8LKoAJYHCSprubm4NxzrQwqlMVBkuqmVRnWr3fFhApncZCkOmnNZdi50ydZqhQWB0mq\ng/xchlZl8EmWKoHFQZKqzsqgAbI4SFJVWRk0BBYHSaqi1ooJK4MGzOIgSVWy0IoJK4MGyOIgSVXh\nXAaNAIuDJI065zJohFgcJGmUWRk0YiwOkjSKrAwaURYHSRo1VgaNMIuDJI0KK4MqwOIgSaPAyqCK\nsDhI0jBZGVQxFgdJGhYrgyrI4iBJg2ZlUIVZHCRpkKwMqjiLgyQNgpVBNWFxkKSytSpDo2FlUOVZ\nHCSpLI1GNmDYsAEmJqwMqgWLgySVIV8ZNm3KvnbAoBqwOEhSkRaqDN6aUI1YHCSpKFYGjQGLgyT1\ny8qgMWJxkKR+uGJCY8biIEm9cMWExpTFQZK65VwGjTGLgyR1Kv/pj85l0JiyOEhSJ6wMEmBxkKSl\nWRmkvVgcJGkxPslSepOui0NEnBQR342IpyNiT0Sc3rb/m83t+df32445ICKujYjnImJ3RNwSEYf1\n+4eRpEL4JEtpUb3cqjgI+AnwOSAtcsztwApgZfM11bb/auA04BPAycARwHd6OBdJKtbsLKxZA5s3\nZ5Vhbg5WrRr2WUkjo+tbFSmlO4A7ACIWHX6/klJ6dqEdEbEMOAc4M6V0d3Pb2cDWiDg+pfRgt+ck\nSX1rNOCSS+CGG2Dduuy/DhikNylrcuQpEbE9Ih6NiOsi4jdy+ybJBix3tTaklB4DngJOLOl8JGlx\nVgapY2UMHG4HzgJ+F/hj4CPA93N1YiXwakppV9vv297cJ0mDsWuXcxmkLhW+qiKldHPul/8UEf8I\nPA6cAvygn/eenp5m+fLle22bmppiaqp9CoUkvQVXTKiGZmZmmJmZ2Wtbo9Eo9HuUvhwzpfRERDwH\nHEM2cNgG7B8Ry9qqw4rmvkVt3LiRtWvXlneykurPuQyqsYV+mJ6fn2dycrKw71H6B0BFxJHAIcAv\nm5u2AK8Dp+aOWQ0cBdxX9vlIGmPOZZD61nVxiIiDyOpBq+m9OyKOBV5ovi4jW1q5rXncl4CfArMA\nKaVdEfEN4KqI2AHsBq4BfuyKCkmlsDJIhenlVsVxZLccUvP11eb2b5F9tsP7ySZHHgw8QzZg+JOU\n0mu595gG3gBuAQ4gW955YQ/nIklLcy6DVKhePsfhbpa+xbGhg/d4Bbio+ZKk4lkZpFL4rApJ9TM7\nm5WFHTusDFLBfDqmpPrIP2Ni9Wo/l0EqgcVBUj04l0EaCIuDpGrzSZbSQFkcJFWXlUEaOIuDpOqx\nMkhDY3GQVC2umJCGyuIgqRoajey2hCsmpKGyOEgafa25DI0GbNqUfe2AQRoKi4Ok0ZWvDBMTWWXw\n1oQ0VBYHSaPJyiCNJIuDpNFiZZBGmsVB0uiwMkgjz+IgafjylaH1uQxWBmkkWRwkDZeVQaoUi4Ok\n4XAug1RJFgdJg2dlkCrL4iBpcPLPmLAySJVkcZA0GHNzcO65Vgap4iwOksrVqgzr17tiQqoBi4Ok\n8rTmMuzc6ZMspZqwOEgqXn4uQ6sy+CRLqRYsDpKKZWWQas3iIKkYVgZpLFgcJPWvtWLCyiDVnsVB\nUu8WWjFhZZBqzeIgqTfOZZDGksVBUnecyyCNNYuDpM5ZGaSxZ3GQ9NasDJKaLA6SlmZlkJRjcZC0\nMCuDpAVYHCS9mZVB0iIsDpJ+zcog6S1YHCRlrAySOmBxkMadlUFSFywO0jizMkjqksVBGkdWBkk9\nsjhI46ZVGRoNK4OkrlkcpHHRaGQDhg0bYGLCyiCpJxYHaRzkK8OmTdnXDhgk9cDiINXZQpXBWxOS\n+mBxkOrKyiCpBBYHqW6sDJJKZHGQ6sQVE5JKZnGQ6sAVE5IGxOIgVZ1zGSQNkMVBqqr8pz86l0HS\ngFgcpCqyMkgaEouDVCVWBklDZnGQqsInWUoaAV0Xh4g4KSK+GxFPR8SeiDh9gWOuiIhnIuKliLgz\nIo5p239ARFwbEc9FxO6IuCUiDuvnDyLVlk+ylDRCerlVcRDwE+BzQGrfGRGXAp8HzgeOB14EZiNi\n/9xhVwOnAZ8ATgaOAL7Tw7lI9TY7C2vWwObNWWWYm4NVq4Z9VpLGWNe3KlJKdwB3AEQs+CPPxcCV\nKaXvNY85C9gOfBy4OSKWAecAZ6aU7m4eczawNSKOTyk92NOfRKqTRgMuuQRuuAHWrcv+64BB0ggo\ndHJkRBwNrATuam1LKe0CHgBObG46jmzAkj/mMeCp3DHS+LIySBphRa+qWEl2+2J72/btzX0AK4BX\nmwOKxY6Rxs+uXc5lkDTyKrWqYnp6muXLl++1bWpqiqmpqSGdkVQQV0xIKsDMzAwzMzN7bWs0GoV+\nj6IHDtuAIKsK+eqwAngod8z+EbGsrTqsaO5b1MaNG1m7dm2BpysNmXMZJBVooR+m5+fnmZycLOx7\nFHqrIqX0BNk//qe2tjUnQ54A3NvctAV4ve2Y1cBRwH1Fno800pzLIKmCui4OEXEQcAxZWQB4d0Qc\nC7yQUvo52VLLL0bEz4AngSuBXwC3QTZZMiK+AVwVETuA3cA1wI9dUaGxYGWQVGG93Ko4DvgB2STI\nBHy1uf1bwDkppS9HxIHA9cDBwI+Aj6aUXs29xzTwBnALcADZ8s4Le/oTSFXiXAZJFdfL5zjczVvc\n4kgpXQ5cvsT+V4CLmi+p/qwMkmqiUqsqpEqanc3Kwo4dVgZJlefTMaWy5J8xsXq1n8sgqRYsDlIZ\nnMsgqaYsDlKRfJKlpJqzOEhFsTJIGgMWB6lfVgZJY8TiIPXDFROSxozFQepFo5HdlnDFhKQxY3GQ\nutWay9BowKZN2dcOGCSNCYuD1Kl8ZZiYyCqDtyYkjRmLg9QJK4MkARYHaWlWBknai8VBWoyVQZLe\nxOIgtctXhtbnMlgZJAmwOEh7szJI0pIsDhI4l0GSOmRxkKwMktQxi4PGV/4ZE1YGSeqIxUHjaW4O\nzj3XyiBJXbI4aLy0KsP69a6YkKQeWBw0PlpzGXbu9EmWktQji4PqLz+XoVUZfJKlJPXE4qB6szJI\nUqEsDqonK4MklcLioPpprZiwMkhS4SwOqo+FVkxYGSSpUBYH1YNzGSRpICwOqjbnMkjSQFkcVF1W\nBkkaOIuDqsfKIElDY3FQtVgZJGmoLA6qBiuDJI0Ei4NGn5VBkkaGxUGjy8ogSSPH4qDRZGWQpJFk\ncdBosTJI0kirVHH4oz+CQw+F/faDfff99Sv/6zfeyF6vv/7rr9t/rRH1q+0w/xC8djp84H/CO98F\n/90Bg6T62W8/+Ku/GvZZ9KZSA4eXXoLnn997QJAfFOzZA/vss/TAYt99/eF15Lz+GjyyFX7+VDYy\nfP/74R0HwmvDPjFJKkdKwz6D3lVq4HDttbB27bDPQoVqzWVoNOD6/wvnnebITpJGmHMcNByNRjZg\n2LABJiacyyBJFVGp4qCayFeGTZuyrx0wSFIlWBw0OAtVBpdZSlKlWBw0GFYGSaoFi4PKZWWQpFqx\nOKg8e62Y8NMfJakOLA4qnismJKm2LA4qlnMZJKnWLA4qRv4ZE85lkKTasjiof1YGSRobFgf1zsog\nSWPH4qDetCrDzp2umJCkMVJ4cYiIyyJiT9vrkbZjroiIZyLipYi4MyKOKfo8VJJ8ZXjve10xIUlj\npqxbFQ8DK4CVzdeHWzsi4lLg88D5wPHAi8BsROxf0rmoKLOzsGYNbN6cVYa5OVi1athnJUkaoLIG\nDq+nlJ5NKf2q+Xoht+9i4MqU0vdSSg8DZwFHAB8v6VzULyuDJKmprIHDb0XE0xHxeETcFBG/CRAR\nR5MViLtaB6aUdgEPACeWdC7qh5VBkpRTxsDhfuAzwHrgAuBo4O8i4iCyQUMCtrf9nu3NfRoVu3ZZ\nGSRJb1L4qoqU0mzulw9HxIPAvwCfBB7t572np6dZvnz5XtumpqaYmprq523VzhUTklRJMzMzzMzM\n7LWt0WgU+j0ipVToGy74TbLBw53ADcDjwAdSSv+Q2/9D4KGU0vQiv38tsGXLli2sXbu29PMdW40G\nXHIJ3HADrFuX/dfbEpJUafPz80xOTgJMppTm+32/0j8AKiLeCRwDPJNSegLYBpya278MOAG4t+xz\n0RKcyyBJ6kAZn+PwlYg4OSJWRcR/Am4FXgM2Nw+5GvhiRPzniPht4EbgF8BtRZ+LOuCKCUlSF8r4\n5MgjgW8DhwDPAvcAH0wpPQ+QUvpyRBwIXA8cDPwI+GhK6dUSzkVLcS6DJKlLZUyOfMuZiimly4HL\ni/7e6pBzGSRJPfJZFeNmdjYrCzt2WBkkSV3z6ZjjIj+XYfVq5zJIknpicRgHzmWQJBXE4lBnrpiQ\nJBXM4lBXVgZJUgksDnVjZZAklcjiUCeumJAklcziUAeNRnZbwhUTkqSSWRyqrjWXodGATZuyrx0w\nSJJKYnGoqnxlmJjIKoO3JiRJJbM4VJGVQZI0JBaHKrEySJKGzOJQFVYGSdIIsDiMunxlaH0ug5VB\nkjQkFodRZmWQJI0Yi8Moci6DJGlEWRxGjZVBkjTCLA6jIv+MCSuDJGlEWRxGwdwcnHuulUGSNPIs\nDsPUqgzr17tiQpJUCRaHYWnNZdi50ydZSpIqw+IwaPm5DK3K4JMsJUkVYXEYJCuDJKniLA6DYGWQ\nJNWExaFsrRUTVgZJUg1YHMqy0IoJK4MkqeIsDmVwLoMkqaYsDkVyLoMkqeYsDkWxMkiSxoDFoV9W\nBknSGLE49MPKIEkaMxaHXlgZJEljyuLQLSuDJGmMWRw6ZWWQJMni0BErgyRJgMVhaVYGSZL2YnFY\njJVBkqQ3sTi0szJIkrQoi0NeqzI0GlYGSZIWYHGAbKDw2c9mlWFiwsogSdIiLA75yrBpU/a1AwZJ\nkhY0vsVhocrgrQlJkpY0nsXByiBJUk/GqzhYGSRJ6sv4FAdXTEiS1Lf6FwdXTEiSVJh6FwfnMkiS\nVKh6Fof8pz86l0GSpMLUrzhYGSRJKk19ioOVQZKk0tVj4DA7C2vWwObN2YqJ2Vk46qhhn1XlzczM\nDPsUxo7XfPC85oPnNa+2oQ4cIuLCiHgiIv41Iu6PiP/Y1Rv4JMtS+T/uwfOaD57XfPC85tU2tIFD\nRPxX4KvAZcB/AP4emI2IQzt6g/bKMDcHq1aVd8KSJGmoxWEauD6ldGNK6VHgAuAl4Jwlf5eVQZKk\noRnKqoqIeBswCfxpa1tKKUXE3wAnLvob770XzjgDdu700x8lSRqCYS3HPBTYF9jetn07sHqB498O\nsPWii+D44+HP/xwOPxweeqjk0xxvjUaD+fn5YZ/GWPGaD57XfPC85oO1devW1pdvL+L9IqVUxPt0\n900jDgeeBk5MKT2Q2/4l4OSU0oltx/834C8He5aSJNXKp1JK3+73TYZVHJ4D3gBWtG1fAWxb4PhZ\n4FPAk8DLpZ6ZJEn18nbgXWT/lvZtKMUBICLuBx5IKV3c/HUATwHXpJS+MpSTkiRJSxrmR05fBfxF\nRGwBHiRbZXEg8BdDPCdJkrSEoQ0cUko3Nz+z4QqyWxQ/AdanlJ4d1jlJkqSlDe1WhSRJqp56PKtC\nkiQNhAMHSZLUsUoMHPp+GJYWFREnRcR3I+LpiNgTEacvcMwVEfFMRLwUEXdGxDHDONc6iIgvRMSD\nEbErIrZHxK0R8Z4FjvOaFyQiLoiIv4+IRvN1b0RsaDvG612iiPgfzf9/uaptu9e9IBFxWfMa51+P\ntB1TyPUe+YFD3w/D0ls5iGxi6ueAN014iYhLgc8D5wPHAy+SXf/9B3mSNXIS8DXgBGAd8DZgLiLe\n0TrAa164nwOXAmvJPur+b4HbImICvN5la/6gdz7Z/3fnt3vdi/cw2WKDlc3Xh1s7Cr3eKaWRfgH3\nA3+W+3UAvwD+eNjnVrcXsAc4vW3bM8B07tfLgH8FPjns863Di+zj1/cAH/aaD/S6Pw+c7fUu/Tq/\nE3gM+F3gB8BVuX1e92Kv9WXA/BL7C7veI10ccg/Duqu1LWV/4qUfhqVCRMTRZKPW/PXfBTyA178o\nB5OVnhfAa162iNgnIs4k+8yYe73epbsW+OuU0t/mN3rdS/NbzdvOj0fETRHxm1D89R7mB0B1otuH\nYalYK8n+UVvo+q8c/OnUS/PTUq8G7kkpte5Fes1LEBFrgPvIPnp3N/D7KaXHIuJEvN6laA7QPgAc\nt8Bu/54X737gM2SF53DgcuDvmn/3C73eoz5wkOrsOuB9wIeGfSJj4FHgWGA58F+AGyPi5OGeUn1F\nxJFkg+J1KaXXhn0+4yCllH8OxcMR8SDwL8Anyf7+F2akb1XQ/cOwVKxtZHNKvP4Fi4ivAx8DTkkp\n/TK3y2tegpTS6ymlf04pPZRS+l9kE/Uuxutdlkng3wLzEfFaRLwGfAS4OCJeJftJ1+teopRSA/gp\ncAwF/z0f6YFDc6S6BTi1ta2Zd08F7h3WeY2LlNITZH+p8td/GdmKAK9/j5qDhjOA30kpPZXf5zUf\nmH2AA7zepfkb4LfJblUc23z9P+Am4NiU0j/jdS9VRLyTbNDwTNF/z6twq8KHYZUoIg4i+8sVzU3v\njohjgRdSSj8ny41fjIifkT3W/EqyVS23DeF0Ky8irgOmgNOBFyOi9RNAI6XUemS817xAEfGnwO1k\nT9/9N8CnyH76/b3mIV7vgqWUXgTaP0PgReD5lNLW5iave4Ei4ivAX5Pdnvh3wP8GXgM2Nw8p7HqP\n/MAh+TCssh1HtkwqNV9fbW7/FnBOSunLEXEgcD3ZCoAfAR9NKb06jJOtgQvIrvMP27afDdwI4DUv\n3GFkf58PBxrAPwC/15rp7/UemL0+J8brXrgjgW8DhwDPAvcAH0wpPQ/FXm8fciVJkjo20nMcJEnS\naHHgIEmSOubAQZIkdcyBgyRJ6pgDB0mS1DEHDpIkqWMOHCRJUsccOEiSpI45cJAkSR1z4CBJkjrm\nwEGSJHXs/wNBceNxEn0FpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1dad793e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result=pd.DataFrame({\"real\":train_label.reshape(-1,),\"predicted\":predicted})\n",
    "df_predict=df_result[\"predicted\"].groupby(df_result['real']).mean()\n",
    "err=Error_compute(df_predict.index,df_predict)\n",
    "print(err)\n",
    "plt_plot(df_predict.index,df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=data_generator(train_data_list_pool,label_data_list_pool,source_dire_list,batch_size=5,time_range=1)\n",
    "i=1\n",
    "for data ,label in a:\n",
    "    print(data.shape,label.shape)\n",
    "    print(i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration.values,60\n",
    "def get_train_data_list_pool(data_dire_list):#获得多个文件夹中的源数据\n",
    "    train_data_list_pool=[]\n",
    "    label_data_list_pool=[]# source data from mutiply floder \n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        train_data_pool_list=[]\n",
    "        label_data_pool_list=[]\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_list=[]\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "            label_data_pool_list.append(residual_life_list)\n",
    "            train_data_pool_list.append(df_60s)\n",
    "        train_data_list_pool.append(train_data_pool_list)\n",
    "        label_data_list_pool.append(label_data_pool_list)\n",
    "    return train_data_list_pool,label_data_list_pool\n",
    "\n",
    "def data_generator(train_data_list_pool,label_data_list_pool,data_dire_list,batch_size=5,time_range=1):\n",
    "#     train_data_list_pool,label_data_list_pool=get_train_data_list_pool(data_dire_list)\n",
    "    \n",
    "    file_list_length=0#获得一个epoch中每个batch需要输出的所有随机样本序列号\n",
    "    for train_data_list in train_data_list_pool:\n",
    "        file_list_length=file_list_length+len(train_data_list)-time_range\n",
    "    batch_random_list_epoch=list(range(1,(file_list_length+1)))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    exit()\n",
    "    for i in range((file_list_length)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "#         label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]#某batch需要输出的样本序列号\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            \n",
    "            upper_bound_file_num=0                               #确定从第几个文件夹中获取数据\n",
    "            lower_bound_file_num=0\n",
    "            for floder_index in range(len(train_data_list_pool)):\n",
    "                upper_bound_file_num=upper_bound_file_num+len(train_data_list_pool[floder_index])-time_range\n",
    "                if start_index<=upper_bound_file_num:\n",
    "                    for minute_index in range(start_index,start_index+time_range):#将time_range分钟的数据连接在一起\n",
    "#                         print(\"floder_index,file_index\",floder_index,minute_index-lower_bound_file_num)\n",
    "                        df_60s=train_data_list_pool[floder_index][minute_index-1-lower_bound_file_num]\n",
    "                        reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                        signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                        residual_life_list.extend(label_data_list_pool[floder_index][minute_index-1-lower_bound_file_num])\n",
    "                    break\n",
    "                lower_bound_file_num=lower_bound_file_num+len(train_data_list_pool[floder_index])-time_range\n",
    "                \n",
    "            resudual_life_array = np.array(residual_life_list)#把上一步中得到的time_range分钟数据作为一条样本加到一个batch组中\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "            label_data=label_data.reshape(-1,60,)\n",
    "            gc.collect()\n",
    "            yield train_data,label_data\n",
    "#         for data,label in zip(train_data,label_data):\n",
    "#             yield data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(range(len(df_signal[\"vibration_1\"])),df_signal[\"vibration_1\"], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dire=os.path.join(source_dire,'0'+str(1),'Sensor')\n",
    "file_list_length=len(os.listdir(file_dire))\n",
    "for file_index in range(1,file_list_length+1):\n",
    "    df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "    print(file_index,df_signal.shape)\n",
    "\n",
    "df_signal=pd.read_csv(os.path.join(file_dire,str(13)+\".csv\"))\n",
    "if df_signal.shape[0]<1536000:\n",
    "    zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "    df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "df_signal=df_signal.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_data_generator(data_dire,batch_size=5,time_range=1,dire_index=1):\n",
    "    file_dire=os.path.join(data_dire,'0'+str(dire_index),'Sensor')\n",
    "    file_list_length=len(os.listdir(file_dire))\n",
    "    batch_random_list_epoch=list(range(1,file_list_length+1-time_range))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    for i in range((file_list_length+1-time_range)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            for file_index in range(start_index,start_index+time_range):\n",
    "                df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "                df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "                reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "            resudual_life_array = np.array(residual_life_list)\n",
    "            gc.collect()\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "        yield train_data,label_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "def get_train_data_pool(data_dire,dire_index=1):\n",
    "    file_dire=os.path.join(data_dire,'0'+str(dire_index),'Sensor')\n",
    "    file_list_length=len(os.listdir(file_dire))\n",
    "    train_data_pool_list=[]\n",
    "    label_data_pool_list=[]\n",
    "    for file_index in range(1,file_list_length+1):\n",
    "        residual_life_list=[]\n",
    "        df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "        df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "        residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "        label_data_pool_list.append(residual_life_list)\n",
    "        train_data_pool_list.append(df_60s)\n",
    "    return train_data_pool_list,label_data_pool_list    \n",
    "def sequence_data_generator_load_memary(data_dire,batch_size=5,time_range=1,dire_index=1):\n",
    "    train_data_pool_list,label_data_pool_list=get_train_data_pool(data_dire)\n",
    "    file_list_length=len(train_data_pool_list)\n",
    "    batch_random_list_epoch=list(range(1,file_list_length+1-time_range))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    for i in range((file_list_length+1-time_range)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            for file_index in range(start_index,start_index+time_range):\n",
    "                df_60s=train_data_pool_list[file_index-1]\n",
    "                reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                residual_life_list.extend(label_data_pool_list[file_index-1])\n",
    "            resudual_life_array = np.array(residual_life_list)\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "            gc.collect()\n",
    "        yield train_data,label_data     "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
