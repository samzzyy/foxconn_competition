{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.fftpack import fft,ifft\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plt_plot(y_real,y_predict):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(range(len(y_real)),y_real, color='r')\n",
    "    ax.plot(range(len(y_predict)),y_predict, color='b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "\n",
    "def load_train_fft_data(data_dire_list,sensor_channel=\"vibration_1\"):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,12800)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    window=25600\n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            fft_train_data_60s=np.array([]).reshape(-1,12800)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5]*seconds_counts).reshape(-1,60,1),axis=0)\n",
    "            for _ in range(60):\n",
    "                freqs=np.fft.fft(df_60s[sensor_channel][window*_:window*(_+1)])\n",
    "                freqs=freqs[0:12800].reshape(-1,12800)\n",
    "                fft_train_data_60s=np.append(fft_train_data_60s,freqs)\n",
    "            train_data_pool_array=np.append(train_data_pool_array,fft_train_data_60s.reshape(-1,60,12800),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "\n",
    "    label_filename = os.path.join(mkdtemp(), 'label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data\n",
    "def load_test_fft_data(data_dire_list,tool_age_list,sensor_channel=\"vibration_1\"):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,12800)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    window=12800\n",
    "    for data_dire,index in zip(data_dire_list,range(len(data_dire_list))):\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            fft_train_data_60s=np.array([]).reshape(-1,12800)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5+tool_age_list[index]]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "#             print(data_dire,str(file_index)+'.csv',(file_list_length-file_index)*5+tool_age_list[index])\n",
    "            for _ in range(60):\n",
    "                freqs=np.fft.fft(df_60s[sensor_channel][window*_:window*(_+1)])\n",
    "                freqs=abs(freqs[0:12800].reshape(-1,12800))\n",
    "                fft_train_data_60s=np.append(fft_train_data_60s,freqs)\n",
    "            train_data_pool_array=np.append(train_data_pool_array,fft_train_data_60s.reshape(-1,60,12800),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'test_source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'test_label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "def load_train_data(data_dire_list):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,25600)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "            train_data_pool_array=np.append(train_data_pool_array,df_60s['vibration_1'].values.reshape(-1,60,25600),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data\n",
    "def load_test_data(data_dire_list,tool_age_list):\n",
    "    train_data_pool_array=np.array([]).reshape(-1,60,25600)\n",
    "    label_data_pool_array=np.array([]).reshape(-1,60,1)\n",
    "    for data_dire,index in zip(data_dire_list,range(len(data_dire_list))):\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_array=np.array([]).reshape(-1,60,1)\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_array=np.append(residual_life_array,np.array([(file_list_length-file_index)*5+tool_age_list[index]]*seconds_counts).reshape(-1,60,1),axis=0)    \n",
    "            train_data_pool_array=np.append(train_data_pool_array,df_60s['vibration_1'].values.reshape(-1,60,25600),axis=0)\n",
    "            label_data_pool_array=np.append(label_data_pool_array,residual_life_array.reshape(-1,60,1),axis=0)\n",
    "    source_filename = os.path.join(mkdtemp(), 'test_source.dat')\n",
    "    source_data= np.memmap(source_filename, dtype='float32', mode='w+', shape=train_data_pool_array.shape)\n",
    "    source_data = train_data_pool_array[:]\n",
    "    \n",
    "    label_filename = os.path.join(mkdtemp(), 'test_label.dat')\n",
    "    label_data= np.memmap(label_filename, dtype='float32', mode='w+', shape=label_data_pool_array.shape)\n",
    "    label_data = label_data_pool_array[:]\n",
    "    return source_data,label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dire = \"../../01-TrainingData-additional/\"\n",
    "source_dire_list=[\n",
    "    \"../../01-TrainingData-additional/01/\",\n",
    "    \"../../01-TrainingData-additional/02/\",\n",
    "  \"../../01-TrainingData-additional/03/\"\n",
    "]\n",
    "test_dire = \"../../02-TestingData-keD1/\"\n",
    "test_dire_list=[\n",
    "    \"../../02-TestingData-keD1/01/\",\n",
    "    \"../../02-TestingData-keD1/02/\",\n",
    "  \"../../02-TestingData-keD1/03/\",\n",
    "    \"../../02-TestingData-keD1/04/\",\n",
    "    \"../../02-TestingData-keD1/05/\"\n",
    "]\n",
    "tool_age_list=[104,52,190,66,40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n",
      "after cut: (1536000, 4) 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data,train_label=load_train_data(source_dire_list)\n",
    "valid_data,valid_label=load_test_data(test_dire_list,tool_age_list)\n",
    "\n",
    "# train_fft_data,train_label=load_train_fft_data(source_dire_list)\n",
    "# valid_fft_data,valid_label=load_test_fft_data(test_dire_list,tool_age_list)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras import models as M\n",
    "from keras import layers as L\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_metric(y_true, y_pred):\n",
    "    y_true, y_pred = tf.reshape(y_true, [-1]), tf.reshape(y_pred, [-1])\n",
    "    er = y_true - y_pred\n",
    "    mask_n, mask_p = (er<=0), (er>0)\n",
    "    er_n, er_p = tf.boolean_mask(er, mask_n), tf.boolean_mask(er, mask_p)\n",
    "    score_n = tf.exp(-tf.log(0.5)*er_n/5)\n",
    "    score_p = tf.exp(tf.log(0.5)*er_p/20)\n",
    "    score = tf.concat([score_n, score_p], 0)\n",
    "    score = tf.reduce_mean(score)*100\n",
    "    return score\n",
    "def cust_loss1(y_real,y_predicted):\n",
    "    y_diff = y_real - y_predicted\n",
    "    loss = tf.where(tf.greater(y_diff, 0),\n",
    "                    -tf.exp(tf.log(0.5) * (y_diff / 20)) +1,\n",
    "                    -tf.exp(-tf.log(0.5) * (y_diff / 5)) +1)\n",
    "    return loss*tf.reduce_max(abs(y_diff))\n",
    "def cust_loss2(y_real,y_predicted):\n",
    "    y_diff = y_real - y_predicted\n",
    "    loss = tf.where(tf.greater(y_diff, 0),\n",
    "                    -tf.log(0.5) * (y_diff / 20),\n",
    "                    tf.log(0.5) * (y_diff / 5))\n",
    "    return loss**2\n",
    "def Error_compute(y_real,y_predicted):\n",
    "    y_diff=y_real-y_predicted\n",
    "    diff_positive=y_diff[y_diff>0]\n",
    "    diff_negitive_0=y_diff[y_diff<=0]\n",
    "    if diff_negitive_0.shape[0] >0:\n",
    "        sum_negitive_error=sum(np.exp(-np.log(0.5)*(diff_negitive_0/5)))\n",
    "    else:\n",
    "        sum_negitive_error=0\n",
    "    if diff_positive.shape[0] >0:\n",
    "        sum_positive_error=sum(np.exp(np.log(0.5)*(diff_positive/20)))\n",
    "    else:\n",
    "        sum_positive_error=0\n",
    "    return (sum_negitive_error+sum_positive_error)/len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import Callback\n",
    "graph = None\n",
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape):\n",
    "    x_input = L.Input(shape=input_shape)\n",
    "    x=L.LSTM(units=300,activation=\"tanh\",return_sequences=True)(x_input)#320\n",
    "    x=L.TimeDistributed(L.Dense(150))(x)\n",
    "    x=L.Dropout(0.5)(x)\n",
    "    x=L.LSTM(units=60,activation=\"tanh\",return_sequences=True)(x)\n",
    "    y=L.TimeDistributed(L.Dense(1))(x)\n",
    "    \n",
    "    model = M.Model(inputs=x_input, outputs=y, name=\"LSTM\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 12800)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 60, 300)           15721200  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 5)             1505      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 5)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 60, 60)            15840     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 15,738,606\n",
      "Trainable params: 15,738,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"./lstm_raw_fft.h5\",monitor='val_evaluation_metric',verbose=1,save_best_only='True',\n",
    "                             mode='max',period=1)\n",
    "# tensorboard = TensorBoard(log_dir='log(./)')\n",
    "callback_lists = [checkpoint]  #因为callback是list型,必须转化为list\n",
    "graph = tf.get_default_graph()\n",
    "model=LSTM_model((60,12800))\n",
    "model.summary()\n",
    "# model=LSTM_model((60,12800))\n",
    "Adam = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam,metrics=[evaluation_metric])\n",
    "# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\n",
    "model.fit(train_fft_data,train_label, epochs=1000, verbose=2,batch_size=25,\n",
    "          validation_data=(valid_fft_data, valid_label),callbacks=callback_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 60, 25600)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 60, 300)           31081200  \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 60, 5)             1505      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60, 5)             0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 60, 60)            15840     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 60, 1)             61        \n",
      "=================================================================\n",
      "Total params: 31,098,606\n",
      "Trainable params: 31,098,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 133 samples, validate on 50 samples\n",
      "Epoch 1/180\n",
      " - 16s - loss: 16319.6926 - evaluation_metric: 14.2063 - val_loss: 15499.1528 - val_evaluation_metric: 5.9902\n",
      "\n",
      "Epoch 00001: val_evaluation_metric improved from -inf to 5.99022, saving model to ./lstm_raw.h5\n",
      "Epoch 2/180\n",
      " - 9s - loss: 16042.1919 - evaluation_metric: 14.4390 - val_loss: 15236.5610 - val_evaluation_metric: 6.2432\n",
      "\n",
      "Epoch 00002: val_evaluation_metric improved from 5.99022 to 6.24322, saving model to ./lstm_raw.h5\n",
      "Epoch 3/180\n",
      " - 10s - loss: 15812.8965 - evaluation_metric: 14.7680 - val_loss: 14995.5981 - val_evaluation_metric: 6.4872\n",
      "\n",
      "Epoch 00003: val_evaluation_metric improved from 6.24322 to 6.48716, saving model to ./lstm_raw.h5\n",
      "Epoch 4/180\n",
      " - 10s - loss: 15573.1160 - evaluation_metric: 14.9947 - val_loss: 14759.3916 - val_evaluation_metric: 6.7359\n",
      "\n",
      "Epoch 00004: val_evaluation_metric improved from 6.48716 to 6.73587, saving model to ./lstm_raw.h5\n",
      "Epoch 5/180\n",
      " - 9s - loss: 15337.2343 - evaluation_metric: 15.1085 - val_loss: 14493.9971 - val_evaluation_metric: 7.0302\n",
      "\n",
      "Epoch 00005: val_evaluation_metric improved from 6.73587 to 7.03018, saving model to ./lstm_raw.h5\n",
      "Epoch 6/180\n",
      " - 8s - loss: 15086.8813 - evaluation_metric: 15.2967 - val_loss: 14230.1465 - val_evaluation_metric: 7.3448\n",
      "\n",
      "Epoch 00006: val_evaluation_metric improved from 7.03018 to 7.34480, saving model to ./lstm_raw.h5\n",
      "Epoch 7/180\n",
      " - 12s - loss: 14849.7135 - evaluation_metric: 15.4118 - val_loss: 14008.4077 - val_evaluation_metric: 7.6263\n",
      "\n",
      "Epoch 00007: val_evaluation_metric improved from 7.34480 to 7.62632, saving model to ./lstm_raw.h5\n",
      "Epoch 8/180\n",
      " - 10s - loss: 14632.6702 - evaluation_metric: 15.5715 - val_loss: 13809.4087 - val_evaluation_metric: 7.8899\n",
      "\n",
      "Epoch 00008: val_evaluation_metric improved from 7.62632 to 7.88987, saving model to ./lstm_raw.h5\n",
      "Epoch 9/180\n",
      " - 11s - loss: 14430.6708 - evaluation_metric: 15.7731 - val_loss: 13622.5913 - val_evaluation_metric: 8.1461\n",
      "\n",
      "Epoch 00009: val_evaluation_metric improved from 7.88987 to 8.14607, saving model to ./lstm_raw.h5\n",
      "Epoch 10/180\n",
      " - 10s - loss: 14235.9618 - evaluation_metric: 15.8238 - val_loss: 13454.8462 - val_evaluation_metric: 8.3843\n",
      "\n",
      "Epoch 00010: val_evaluation_metric improved from 8.14607 to 8.38433, saving model to ./lstm_raw.h5\n",
      "Epoch 11/180\n",
      " - 12s - loss: 14064.0396 - evaluation_metric: 15.7162 - val_loss: 13302.5488 - val_evaluation_metric: 8.6077\n",
      "\n",
      "Epoch 00011: val_evaluation_metric improved from 8.38433 to 8.60773, saving model to ./lstm_raw.h5\n",
      "Epoch 12/180\n",
      " - 7s - loss: 13909.8657 - evaluation_metric: 15.8126 - val_loss: 13159.3433 - val_evaluation_metric: 8.8249\n",
      "\n",
      "Epoch 00012: val_evaluation_metric improved from 8.60773 to 8.82489, saving model to ./lstm_raw.h5\n",
      "Epoch 13/180\n",
      " - 7s - loss: 13776.5985 - evaluation_metric: 15.8619 - val_loss: 13031.9092 - val_evaluation_metric: 9.0228\n",
      "\n",
      "Epoch 00013: val_evaluation_metric improved from 8.82489 to 9.02282, saving model to ./lstm_raw.h5\n",
      "Epoch 14/180\n",
      " - 7s - loss: 13660.3373 - evaluation_metric: 15.9350 - val_loss: 12907.3608 - val_evaluation_metric: 9.2212\n",
      "\n",
      "Epoch 00014: val_evaluation_metric improved from 9.02282 to 9.22115, saving model to ./lstm_raw.h5\n",
      "Epoch 15/180\n",
      " - 7s - loss: 13540.7840 - evaluation_metric: 16.0652 - val_loss: 12791.7505 - val_evaluation_metric: 9.4102\n",
      "\n",
      "Epoch 00015: val_evaluation_metric improved from 9.22115 to 9.41024, saving model to ./lstm_raw.h5\n",
      "Epoch 16/180\n",
      " - 8s - loss: 13429.5493 - evaluation_metric: 16.0105 - val_loss: 12689.6040 - val_evaluation_metric: 9.5816\n",
      "\n",
      "Epoch 00016: val_evaluation_metric improved from 9.41024 to 9.58155, saving model to ./lstm_raw.h5\n",
      "Epoch 17/180\n",
      " - 8s - loss: 13335.4513 - evaluation_metric: 16.0176 - val_loss: 12596.6333 - val_evaluation_metric: 9.7403\n",
      "\n",
      "Epoch 00017: val_evaluation_metric improved from 9.58155 to 9.74028, saving model to ./lstm_raw.h5\n",
      "Epoch 18/180\n",
      " - 8s - loss: 13245.7554 - evaluation_metric: 15.9949 - val_loss: 12506.7588 - val_evaluation_metric: 9.8976\n",
      "\n",
      "Epoch 00018: val_evaluation_metric improved from 9.74028 to 9.89757, saving model to ./lstm_raw.h5\n",
      "Epoch 19/180\n",
      " - 8s - loss: 13160.6367 - evaluation_metric: 15.9603 - val_loss: 12418.5103 - val_evaluation_metric: 10.0545\n",
      "\n",
      "Epoch 00019: val_evaluation_metric improved from 9.89757 to 10.05449, saving model to ./lstm_raw.h5\n",
      "Epoch 20/180\n",
      " - 7s - loss: 13078.4193 - evaluation_metric: 15.9663 - val_loss: 12331.9922 - val_evaluation_metric: 10.2117\n",
      "\n",
      "Epoch 00020: val_evaluation_metric improved from 10.05449 to 10.21173, saving model to ./lstm_raw.h5\n",
      "Epoch 21/180\n",
      " - 8s - loss: 12995.8017 - evaluation_metric: 15.9693 - val_loss: 12247.6382 - val_evaluation_metric: 10.3681\n",
      "\n",
      "Epoch 00021: val_evaluation_metric improved from 10.21173 to 10.36806, saving model to ./lstm_raw.h5\n",
      "Epoch 22/180\n",
      " - 8s - loss: 12915.8447 - evaluation_metric: 16.0050 - val_loss: 12163.9458 - val_evaluation_metric: 10.5268\n",
      "\n",
      "Epoch 00022: val_evaluation_metric improved from 10.36806 to 10.52682, saving model to ./lstm_raw.h5\n",
      "Epoch 23/180\n",
      " - 7s - loss: 12834.9876 - evaluation_metric: 16.0060 - val_loss: 12083.6479 - val_evaluation_metric: 10.6822\n",
      "\n",
      "Epoch 00023: val_evaluation_metric improved from 10.52682 to 10.68222, saving model to ./lstm_raw.h5\n",
      "Epoch 24/180\n",
      " - 8s - loss: 12764.6691 - evaluation_metric: 16.0606 - val_loss: 12003.9575 - val_evaluation_metric: 10.8395\n",
      "\n",
      "Epoch 00024: val_evaluation_metric improved from 10.68222 to 10.83954, saving model to ./lstm_raw.h5\n",
      "Epoch 25/180\n",
      " - 9s - loss: 12681.4733 - evaluation_metric: 16.1672 - val_loss: 11927.3711 - val_evaluation_metric: 10.9935\n",
      "\n",
      "Epoch 00025: val_evaluation_metric improved from 10.83954 to 10.99354, saving model to ./lstm_raw.h5\n",
      "Epoch 26/180\n",
      " - 10s - loss: 12604.9486 - evaluation_metric: 16.1929 - val_loss: 11852.3926 - val_evaluation_metric: 11.1472\n",
      "\n",
      "Epoch 00026: val_evaluation_metric improved from 10.99354 to 11.14722, saving model to ./lstm_raw.h5\n",
      "Epoch 27/180\n",
      " - 9s - loss: 12540.5519 - evaluation_metric: 16.2311 - val_loss: 11778.3047 - val_evaluation_metric: 11.3018\n",
      "\n",
      "Epoch 00027: val_evaluation_metric improved from 11.14722 to 11.30184, saving model to ./lstm_raw.h5\n",
      "Epoch 28/180\n",
      " - 9s - loss: 12464.0751 - evaluation_metric: 16.1638 - val_loss: 11705.3662 - val_evaluation_metric: 11.4569\n",
      "\n",
      "Epoch 00028: val_evaluation_metric improved from 11.30184 to 11.45686, saving model to ./lstm_raw.h5\n",
      "Epoch 29/180\n",
      " - 9s - loss: 12395.5246 - evaluation_metric: 16.1355 - val_loss: 11633.3774 - val_evaluation_metric: 11.6125\n",
      "\n",
      "Epoch 00029: val_evaluation_metric improved from 11.45686 to 11.61249, saving model to ./lstm_raw.h5\n",
      "Epoch 30/180\n",
      " - 9s - loss: 12325.9754 - evaluation_metric: 16.0820 - val_loss: 11561.4819 - val_evaluation_metric: 11.7707\n",
      "\n",
      "Epoch 00030: val_evaluation_metric improved from 11.61249 to 11.77066, saving model to ./lstm_raw.h5\n",
      "Epoch 31/180\n",
      " - 10s - loss: 12257.8340 - evaluation_metric: 16.0665 - val_loss: 11491.8135 - val_evaluation_metric: 11.9266\n",
      "\n",
      "Epoch 00031: val_evaluation_metric improved from 11.77066 to 11.92658, saving model to ./lstm_raw.h5\n",
      "Epoch 32/180\n",
      " - 9s - loss: 12189.2985 - evaluation_metric: 16.0581 - val_loss: 11422.5991 - val_evaluation_metric: 12.0842\n",
      "\n",
      "Epoch 00032: val_evaluation_metric improved from 11.92658 to 12.08421, saving model to ./lstm_raw.h5\n",
      "Epoch 33/180\n",
      " - 9s - loss: 12124.6326 - evaluation_metric: 16.0647 - val_loss: 11353.7363 - val_evaluation_metric: 12.2438\n",
      "\n",
      "Epoch 00033: val_evaluation_metric improved from 12.08421 to 12.24378, saving model to ./lstm_raw.h5\n",
      "Epoch 34/180\n",
      " - 8s - loss: 12052.4792 - evaluation_metric: 16.0884 - val_loss: 11284.8574 - val_evaluation_metric: 12.4063\n",
      "\n",
      "Epoch 00034: val_evaluation_metric improved from 12.24378 to 12.40630, saving model to ./lstm_raw.h5\n",
      "Epoch 35/180\n",
      " - 9s - loss: 11990.1603 - evaluation_metric: 16.0977 - val_loss: 11215.5439 - val_evaluation_metric: 12.5727\n",
      "\n",
      "Epoch 00035: val_evaluation_metric improved from 12.40630 to 12.57271, saving model to ./lstm_raw.h5\n",
      "Epoch 36/180\n",
      " - 10s - loss: 11922.3962 - evaluation_metric: 16.1356 - val_loss: 11145.4780 - val_evaluation_metric: 12.7440\n",
      "\n",
      "Epoch 00036: val_evaluation_metric improved from 12.57271 to 12.74403, saving model to ./lstm_raw.h5\n",
      "Epoch 37/180\n",
      " - 10s - loss: 11851.3605 - evaluation_metric: 16.1721 - val_loss: 11078.1938 - val_evaluation_metric: 12.9114\n",
      "\n",
      "Epoch 00037: val_evaluation_metric improved from 12.74403 to 12.91143, saving model to ./lstm_raw.h5\n",
      "Epoch 38/180\n",
      " - 11s - loss: 11794.9569 - evaluation_metric: 16.2269 - val_loss: 11010.7480 - val_evaluation_metric: 13.0821\n",
      "\n",
      "Epoch 00038: val_evaluation_metric improved from 12.91143 to 13.08208, saving model to ./lstm_raw.h5\n",
      "Epoch 39/180\n",
      " - 11s - loss: 11725.7880 - evaluation_metric: 16.2784 - val_loss: 10942.2100 - val_evaluation_metric: 13.2585\n",
      "\n",
      "Epoch 00039: val_evaluation_metric improved from 13.08208 to 13.25852, saving model to ./lstm_raw.h5\n",
      "Epoch 40/180\n",
      " - 7s - loss: 11658.3083 - evaluation_metric: 16.3074 - val_loss: 10875.1313 - val_evaluation_metric: 13.4342\n",
      "\n",
      "Epoch 00040: val_evaluation_metric improved from 13.25852 to 13.43423, saving model to ./lstm_raw.h5\n",
      "Epoch 41/180\n",
      " - 7s - loss: 11592.3910 - evaluation_metric: 16.2831 - val_loss: 10807.5161 - val_evaluation_metric: 13.6144\n",
      "\n",
      "Epoch 00041: val_evaluation_metric improved from 13.43423 to 13.61445, saving model to ./lstm_raw.h5\n",
      "Epoch 42/180\n",
      " - 7s - loss: 11530.0153 - evaluation_metric: 16.1942 - val_loss: 10742.4131 - val_evaluation_metric: 13.7911\n",
      "\n",
      "Epoch 00042: val_evaluation_metric improved from 13.61445 to 13.79112, saving model to ./lstm_raw.h5\n",
      "Epoch 43/180\n",
      " - 8s - loss: 11467.7120 - evaluation_metric: 16.1933 - val_loss: 10678.3042 - val_evaluation_metric: 13.9680\n",
      "\n",
      "Epoch 00043: val_evaluation_metric improved from 13.79112 to 13.96803, saving model to ./lstm_raw.h5\n",
      "Epoch 44/180\n",
      " - 8s - loss: 11403.6300 - evaluation_metric: 16.1304 - val_loss: 10614.8418 - val_evaluation_metric: 14.1461\n",
      "\n",
      "Epoch 00044: val_evaluation_metric improved from 13.96803 to 14.14615, saving model to ./lstm_raw.h5\n",
      "Epoch 45/180\n",
      " - 7s - loss: 11344.2536 - evaluation_metric: 16.1180 - val_loss: 10550.3257 - val_evaluation_metric: 14.3304\n",
      "\n",
      "Epoch 00045: val_evaluation_metric improved from 14.14615 to 14.33042, saving model to ./lstm_raw.h5\n",
      "Epoch 46/180\n",
      " - 8s - loss: 11285.9583 - evaluation_metric: 16.1436 - val_loss: 10487.3511 - val_evaluation_metric: 14.5134\n",
      "\n",
      "Epoch 00046: val_evaluation_metric improved from 14.33042 to 14.51339, saving model to ./lstm_raw.h5\n",
      "Epoch 47/180\n",
      " - 8s - loss: 11223.6787 - evaluation_metric: 16.1253 - val_loss: 10425.0398 - val_evaluation_metric: 14.6975\n",
      "\n",
      "Epoch 00047: val_evaluation_metric improved from 14.51339 to 14.69755, saving model to ./lstm_raw.h5\n",
      "Epoch 48/180\n",
      " - 8s - loss: 11156.1292 - evaluation_metric: 16.1581 - val_loss: 10363.2676 - val_evaluation_metric: 14.8832\n",
      "\n",
      "Epoch 00048: val_evaluation_metric improved from 14.69755 to 14.88324, saving model to ./lstm_raw.h5\n",
      "Epoch 49/180\n",
      " - 8s - loss: 11108.0686 - evaluation_metric: 16.1317 - val_loss: 10300.7007 - val_evaluation_metric: 15.0745\n",
      "\n",
      "Epoch 00049: val_evaluation_metric improved from 14.88324 to 15.07448, saving model to ./lstm_raw.h5\n",
      "Epoch 50/180\n",
      " - 9s - loss: 11045.9647 - evaluation_metric: 16.1653 - val_loss: 10240.1523 - val_evaluation_metric: 15.2627\n",
      "\n",
      "Epoch 00050: val_evaluation_metric improved from 15.07448 to 15.26273, saving model to ./lstm_raw.h5\n",
      "Epoch 51/180\n",
      " - 7s - loss: 10982.3283 - evaluation_metric: 16.2657 - val_loss: 10179.9519 - val_evaluation_metric: 15.4531\n",
      "\n",
      "Epoch 00051: val_evaluation_metric improved from 15.26273 to 15.45311, saving model to ./lstm_raw.h5\n",
      "Epoch 52/180\n",
      " - 7s - loss: 10929.5816 - evaluation_metric: 16.2450 - val_loss: 10119.0918 - val_evaluation_metric: 15.6489\n",
      "\n",
      "Epoch 00052: val_evaluation_metric improved from 15.45311 to 15.64888, saving model to ./lstm_raw.h5\n",
      "Epoch 53/180\n",
      " - 7s - loss: 10871.0786 - evaluation_metric: 16.3033 - val_loss: 10061.9976 - val_evaluation_metric: 15.8356\n",
      "\n",
      "Epoch 00053: val_evaluation_metric improved from 15.64888 to 15.83558, saving model to ./lstm_raw.h5\n",
      "Epoch 54/180\n",
      " - 8s - loss: 10814.9751 - evaluation_metric: 16.3436 - val_loss: 10003.9529 - val_evaluation_metric: 16.0285\n",
      "\n",
      "Epoch 00054: val_evaluation_metric improved from 15.83558 to 16.02848, saving model to ./lstm_raw.h5\n",
      "Epoch 55/180\n",
      " - 9s - loss: 10760.8317 - evaluation_metric: 16.3290 - val_loss: 9945.9749 - val_evaluation_metric: 16.2244\n",
      "\n",
      "Epoch 00055: val_evaluation_metric improved from 16.02848 to 16.22442, saving model to ./lstm_raw.h5\n",
      "Epoch 56/180\n",
      " - 10s - loss: 10703.2724 - evaluation_metric: 16.2151 - val_loss: 9889.2756 - val_evaluation_metric: 16.4192\n",
      "\n",
      "Epoch 00056: val_evaluation_metric improved from 16.22442 to 16.41921, saving model to ./lstm_raw.h5\n",
      "Epoch 57/180\n",
      " - 10s - loss: 10653.4922 - evaluation_metric: 16.1714 - val_loss: 9832.3230 - val_evaluation_metric: 16.6180\n",
      "\n",
      "Epoch 00057: val_evaluation_metric improved from 16.41921 to 16.61803, saving model to ./lstm_raw.h5\n",
      "Epoch 58/180\n",
      " - 9s - loss: 10591.2973 - evaluation_metric: 16.1457 - val_loss: 9776.2429 - val_evaluation_metric: 16.8170\n",
      "\n",
      "Epoch 00058: val_evaluation_metric improved from 16.61803 to 16.81698, saving model to ./lstm_raw.h5\n",
      "Epoch 59/180\n",
      " - 10s - loss: 10541.9772 - evaluation_metric: 16.1320 - val_loss: 9719.6741 - val_evaluation_metric: 17.0210\n",
      "\n",
      "Epoch 00059: val_evaluation_metric improved from 16.81698 to 17.02096, saving model to ./lstm_raw.h5\n",
      "Epoch 60/180\n",
      " - 10s - loss: 10487.3580 - evaluation_metric: 16.1826 - val_loss: 9663.9761 - val_evaluation_metric: 17.2252\n",
      "\n",
      "Epoch 00060: val_evaluation_metric improved from 17.02096 to 17.22516, saving model to ./lstm_raw.h5\n",
      "Epoch 61/180\n",
      " - 10s - loss: 10432.7324 - evaluation_metric: 16.1213 - val_loss: 9612.1414 - val_evaluation_metric: 17.4182\n",
      "\n",
      "Epoch 00061: val_evaluation_metric improved from 17.22516 to 17.41824, saving model to ./lstm_raw.h5\n",
      "Epoch 62/180\n",
      " - 11s - loss: 10379.1447 - evaluation_metric: 16.1425 - val_loss: 9558.7256 - val_evaluation_metric: 17.6204\n",
      "\n",
      "Epoch 00062: val_evaluation_metric improved from 17.41824 to 17.62037, saving model to ./lstm_raw.h5\n",
      "Epoch 63/180\n",
      " - 9s - loss: 10325.9684 - evaluation_metric: 16.1123 - val_loss: 9505.2273 - val_evaluation_metric: 17.8261\n",
      "\n",
      "Epoch 00063: val_evaluation_metric improved from 17.62037 to 17.82606, saving model to ./lstm_raw.h5\n",
      "Epoch 64/180\n",
      " - 11s - loss: 10274.5924 - evaluation_metric: 16.1577 - val_loss: 9451.9714 - val_evaluation_metric: 18.0341\n",
      "\n",
      "Epoch 00064: val_evaluation_metric improved from 17.82606 to 18.03411, saving model to ./lstm_raw.h5\n",
      "Epoch 65/180\n",
      " - 11s - loss: 10224.6260 - evaluation_metric: 16.1999 - val_loss: 9397.8723 - val_evaluation_metric: 18.2488\n",
      "\n",
      "Epoch 00065: val_evaluation_metric improved from 18.03411 to 18.24885, saving model to ./lstm_raw.h5\n",
      "Epoch 66/180\n",
      " - 7s - loss: 10173.7486 - evaluation_metric: 16.2668 - val_loss: 9343.2217 - val_evaluation_metric: 18.4693\n",
      "\n",
      "Epoch 00066: val_evaluation_metric improved from 18.24885 to 18.46934, saving model to ./lstm_raw.h5\n",
      "Epoch 67/180\n",
      " - 8s - loss: 10123.8231 - evaluation_metric: 16.3090 - val_loss: 9289.8145 - val_evaluation_metric: 18.6883\n",
      "\n",
      "Epoch 00067: val_evaluation_metric improved from 18.46934 to 18.68834, saving model to ./lstm_raw.h5\n",
      "Epoch 68/180\n",
      " - 8s - loss: 10072.9582 - evaluation_metric: 16.3774 - val_loss: 9236.4958 - val_evaluation_metric: 18.9105\n",
      "\n",
      "Epoch 00068: val_evaluation_metric improved from 18.68834 to 18.91054, saving model to ./lstm_raw.h5\n",
      "Epoch 69/180\n",
      " - 8s - loss: 10023.3915 - evaluation_metric: 16.3060 - val_loss: 9183.4558 - val_evaluation_metric: 19.1352\n",
      "\n",
      "Epoch 00069: val_evaluation_metric improved from 18.91054 to 19.13520, saving model to ./lstm_raw.h5\n",
      "Epoch 70/180\n",
      " - 7s - loss: 9970.6751 - evaluation_metric: 16.2918 - val_loss: 9131.0754 - val_evaluation_metric: 19.3607\n",
      "\n",
      "Epoch 00070: val_evaluation_metric improved from 19.13520 to 19.36071, saving model to ./lstm_raw.h5\n",
      "Epoch 71/180\n",
      " - 8s - loss: 9920.7423 - evaluation_metric: 16.2650 - val_loss: 9079.4893 - val_evaluation_metric: 19.5864\n",
      "\n",
      "Epoch 00071: val_evaluation_metric improved from 19.36071 to 19.58642, saving model to ./lstm_raw.h5\n",
      "Epoch 72/180\n",
      " - 8s - loss: 9870.9741 - evaluation_metric: 16.1835 - val_loss: 9028.4224 - val_evaluation_metric: 19.8135\n",
      "\n",
      "Epoch 00072: val_evaluation_metric improved from 19.58642 to 19.81346, saving model to ./lstm_raw.h5\n",
      "Epoch 73/180\n",
      " - 8s - loss: 9821.0306 - evaluation_metric: 16.1968 - val_loss: 8978.8870 - val_evaluation_metric: 20.0371\n",
      "\n",
      "Epoch 00073: val_evaluation_metric improved from 19.81346 to 20.03713, saving model to ./lstm_raw.h5\n",
      "Epoch 74/180\n",
      " - 8s - loss: 9771.0468 - evaluation_metric: 16.1729 - val_loss: 8930.1885 - val_evaluation_metric: 20.2605\n",
      "\n",
      "Epoch 00074: val_evaluation_metric improved from 20.03713 to 20.26048, saving model to ./lstm_raw.h5\n",
      "Epoch 75/180\n",
      " - 8s - loss: 9728.2102 - evaluation_metric: 16.1422 - val_loss: 8882.6646 - val_evaluation_metric: 20.4818\n",
      "\n",
      "Epoch 00075: val_evaluation_metric improved from 20.26048 to 20.48181, saving model to ./lstm_raw.h5\n",
      "Epoch 76/180\n",
      " - 7s - loss: 9682.6377 - evaluation_metric: 16.1521 - val_loss: 8833.0820 - val_evaluation_metric: 20.7163\n",
      "\n",
      "Epoch 00076: val_evaluation_metric improved from 20.48181 to 20.71632, saving model to ./lstm_raw.h5\n",
      "Epoch 77/180\n",
      " - 9s - loss: 9631.4419 - evaluation_metric: 16.1366 - val_loss: 8784.4604 - val_evaluation_metric: 20.9499\n",
      "\n",
      "Epoch 00077: val_evaluation_metric improved from 20.71632 to 20.94987, saving model to ./lstm_raw.h5\n",
      "Epoch 78/180\n",
      " - 8s - loss: 9587.9874 - evaluation_metric: 16.1332 - val_loss: 8736.1360 - val_evaluation_metric: 21.1857\n",
      "\n",
      "Epoch 00078: val_evaluation_metric improved from 20.94987 to 21.18566, saving model to ./lstm_raw.h5\n",
      "Epoch 79/180\n",
      " - 8s - loss: 9551.7903 - evaluation_metric: 16.1737 - val_loss: 8688.9404 - val_evaluation_metric: 21.4195\n",
      "\n",
      "Epoch 00079: val_evaluation_metric improved from 21.18566 to 21.41954, saving model to ./lstm_raw.h5\n",
      "Epoch 80/180\n",
      " - 8s - loss: 9499.4759 - evaluation_metric: 16.1885 - val_loss: 8642.4131 - val_evaluation_metric: 21.6536\n",
      "\n",
      "Epoch 00080: val_evaluation_metric improved from 21.41954 to 21.65358, saving model to ./lstm_raw.h5\n",
      "Epoch 81/180\n",
      " - 8s - loss: 9453.3698 - evaluation_metric: 16.2099 - val_loss: 8596.4702 - val_evaluation_metric: 21.8882\n",
      "\n",
      "Epoch 00081: val_evaluation_metric improved from 21.65358 to 21.88824, saving model to ./lstm_raw.h5\n",
      "Epoch 82/180\n",
      " - 8s - loss: 9411.4576 - evaluation_metric: 16.2959 - val_loss: 8551.3445 - val_evaluation_metric: 22.1222\n",
      "\n",
      "Epoch 00082: val_evaluation_metric improved from 21.88824 to 22.12218, saving model to ./lstm_raw.h5\n",
      "Epoch 83/180\n",
      " - 8s - loss: 9363.9995 - evaluation_metric: 16.3104 - val_loss: 8504.5278 - val_evaluation_metric: 22.3686\n",
      "\n",
      "Epoch 00083: val_evaluation_metric improved from 22.12218 to 22.36864, saving model to ./lstm_raw.h5\n",
      "Epoch 84/180\n",
      " - 9s - loss: 9322.5479 - evaluation_metric: 16.3724 - val_loss: 8457.9067 - val_evaluation_metric: 22.5398\n",
      "\n",
      "Epoch 00084: val_evaluation_metric improved from 22.36864 to 22.53980, saving model to ./lstm_raw.h5\n",
      "Epoch 85/180\n",
      " - 10s - loss: 9273.9223 - evaluation_metric: 16.3516 - val_loss: 8412.3032 - val_evaluation_metric: 22.6862\n",
      "\n",
      "Epoch 00085: val_evaluation_metric improved from 22.53980 to 22.68621, saving model to ./lstm_raw.h5\n",
      "Epoch 86/180\n",
      " - 10s - loss: 9236.9404 - evaluation_metric: 16.2230 - val_loss: 8366.7104 - val_evaluation_metric: 22.8391\n",
      "\n",
      "Epoch 00086: val_evaluation_metric improved from 22.68621 to 22.83911, saving model to ./lstm_raw.h5\n",
      "Epoch 87/180\n",
      " - 11s - loss: 9194.6397 - evaluation_metric: 16.2139 - val_loss: 8321.1716 - val_evaluation_metric: 22.9983\n",
      "\n",
      "Epoch 00087: val_evaluation_metric improved from 22.83911 to 22.99833, saving model to ./lstm_raw.h5\n",
      "Epoch 88/180\n",
      " - 11s - loss: 9147.3859 - evaluation_metric: 16.1940 - val_loss: 8275.7202 - val_evaluation_metric: 23.1635\n",
      "\n",
      "Epoch 00088: val_evaluation_metric improved from 22.99833 to 23.16352, saving model to ./lstm_raw.h5\n",
      "Epoch 89/180\n",
      " - 8s - loss: 9104.0193 - evaluation_metric: 16.1380 - val_loss: 8231.3501 - val_evaluation_metric: 23.3294\n",
      "\n",
      "Epoch 00089: val_evaluation_metric improved from 23.16352 to 23.32944, saving model to ./lstm_raw.h5\n",
      "Epoch 90/180\n",
      " - 9s - loss: 9059.8198 - evaluation_metric: 16.1722 - val_loss: 8186.7979 - val_evaluation_metric: 23.5022\n",
      "\n",
      "Epoch 00090: val_evaluation_metric improved from 23.32944 to 23.50225, saving model to ./lstm_raw.h5\n",
      "Epoch 91/180\n",
      " - 8s - loss: 9012.3574 - evaluation_metric: 16.1362 - val_loss: 8142.4790 - val_evaluation_metric: 23.6803\n",
      "\n",
      "Epoch 00091: val_evaluation_metric improved from 23.50225 to 23.68031, saving model to ./lstm_raw.h5\n",
      "Epoch 92/180\n",
      " - 9s - loss: 8973.2387 - evaluation_metric: 16.1434 - val_loss: 8098.4080 - val_evaluation_metric: 23.8634\n",
      "\n",
      "Epoch 00092: val_evaluation_metric improved from 23.68031 to 23.86343, saving model to ./lstm_raw.h5\n",
      "Epoch 93/180\n",
      " - 11s - loss: 8929.6130 - evaluation_metric: 16.1737 - val_loss: 8055.4919 - val_evaluation_metric: 24.0476\n",
      "\n",
      "Epoch 00093: val_evaluation_metric improved from 23.86343 to 24.04759, saving model to ./lstm_raw.h5\n",
      "Epoch 94/180\n",
      " - 10s - loss: 8892.7119 - evaluation_metric: 16.1794 - val_loss: 8011.8003 - val_evaluation_metric: 24.2410\n",
      "\n",
      "Epoch 00094: val_evaluation_metric improved from 24.04759 to 24.24100, saving model to ./lstm_raw.h5\n",
      "Epoch 95/180\n",
      " - 11s - loss: 8847.2126 - evaluation_metric: 16.1961 - val_loss: 7968.4927 - val_evaluation_metric: 24.4386\n",
      "\n",
      "Epoch 00095: val_evaluation_metric improved from 24.24100 to 24.43856, saving model to ./lstm_raw.h5\n",
      "Epoch 96/180\n",
      " - 12s - loss: 8806.1224 - evaluation_metric: 16.1892 - val_loss: 7926.4902 - val_evaluation_metric: 24.6358\n",
      "\n",
      "Epoch 00096: val_evaluation_metric improved from 24.43856 to 24.63578, saving model to ./lstm_raw.h5\n",
      "Epoch 97/180\n",
      " - 7s - loss: 8766.6009 - evaluation_metric: 16.2551 - val_loss: 7885.8357 - val_evaluation_metric: 24.8319\n",
      "\n",
      "Epoch 00097: val_evaluation_metric improved from 24.63578 to 24.83191, saving model to ./lstm_raw.h5\n",
      "Epoch 98/180\n",
      " - 7s - loss: 8726.4755 - evaluation_metric: 16.2859 - val_loss: 7844.3306 - val_evaluation_metric: 25.0375\n",
      "\n",
      "Epoch 00098: val_evaluation_metric improved from 24.83191 to 25.03750, saving model to ./lstm_raw.h5\n",
      "Epoch 99/180\n",
      " - 7s - loss: 8689.3901 - evaluation_metric: 16.2925 - val_loss: 7803.6074 - val_evaluation_metric: 25.2445\n",
      "\n",
      "Epoch 00099: val_evaluation_metric improved from 25.03750 to 25.24450, saving model to ./lstm_raw.h5\n",
      "Epoch 100/180\n",
      " - 7s - loss: 8651.5954 - evaluation_metric: 16.3653 - val_loss: 7762.4224 - val_evaluation_metric: 25.3931\n",
      "\n",
      "Epoch 00100: val_evaluation_metric improved from 25.24450 to 25.39315, saving model to ./lstm_raw.h5\n",
      "Epoch 101/180\n",
      " - 7s - loss: 8610.5663 - evaluation_metric: 16.3147 - val_loss: 7722.4624 - val_evaluation_metric: 25.5109\n",
      "\n",
      "Epoch 00101: val_evaluation_metric improved from 25.39315 to 25.51093, saving model to ./lstm_raw.h5\n",
      "Epoch 102/180\n",
      " - 8s - loss: 8572.2502 - evaluation_metric: 16.2821 - val_loss: 7682.4556 - val_evaluation_metric: 25.6363\n",
      "\n",
      "Epoch 00102: val_evaluation_metric improved from 25.51093 to 25.63629, saving model to ./lstm_raw.h5\n",
      "Epoch 103/180\n",
      " - 8s - loss: 8531.3844 - evaluation_metric: 16.2454 - val_loss: 7644.2029 - val_evaluation_metric: 25.7632\n",
      "\n",
      "Epoch 00103: val_evaluation_metric improved from 25.63629 to 25.76316, saving model to ./lstm_raw.h5\n",
      "Epoch 104/180\n",
      " - 8s - loss: 8493.8366 - evaluation_metric: 16.2020 - val_loss: 7604.0781 - val_evaluation_metric: 25.9036\n",
      "\n",
      "Epoch 00104: val_evaluation_metric improved from 25.76316 to 25.90356, saving model to ./lstm_raw.h5\n",
      "Epoch 105/180\n",
      " - 8s - loss: 8461.2398 - evaluation_metric: 16.1621 - val_loss: 7563.2629 - val_evaluation_metric: 26.0538\n",
      "\n",
      "Epoch 00105: val_evaluation_metric improved from 25.90356 to 26.05384, saving model to ./lstm_raw.h5\n",
      "Epoch 106/180\n",
      " - 8s - loss: 8424.6556 - evaluation_metric: 16.1701 - val_loss: 7523.9365 - val_evaluation_metric: 26.2044\n",
      "\n",
      "Epoch 00106: val_evaluation_metric improved from 26.05384 to 26.20440, saving model to ./lstm_raw.h5\n",
      "Epoch 107/180\n",
      " - 8s - loss: 8382.8158 - evaluation_metric: 16.1148 - val_loss: 7485.1912 - val_evaluation_metric: 26.3597\n",
      "\n",
      "Epoch 00107: val_evaluation_metric improved from 26.20440 to 26.35969, saving model to ./lstm_raw.h5\n",
      "Epoch 108/180\n",
      " - 9s - loss: 8347.3541 - evaluation_metric: 16.1104 - val_loss: 7446.8855 - val_evaluation_metric: 26.5199\n",
      "\n",
      "Epoch 00108: val_evaluation_metric improved from 26.35969 to 26.51994, saving model to ./lstm_raw.h5\n",
      "Epoch 109/180\n",
      " - 8s - loss: 8311.1861 - evaluation_metric: 16.1293 - val_loss: 7409.3408 - val_evaluation_metric: 26.6835\n",
      "\n",
      "Epoch 00109: val_evaluation_metric improved from 26.51994 to 26.68351, saving model to ./lstm_raw.h5\n",
      "Epoch 110/180\n",
      " - 8s - loss: 8274.1990 - evaluation_metric: 16.1364 - val_loss: 7372.1233 - val_evaluation_metric: 26.8520\n",
      "\n",
      "Epoch 00110: val_evaluation_metric improved from 26.68351 to 26.85195, saving model to ./lstm_raw.h5\n",
      "Epoch 111/180\n",
      " - 8s - loss: 8237.1193 - evaluation_metric: 16.1771 - val_loss: 7333.3821 - val_evaluation_metric: 27.0339\n",
      "\n",
      "Epoch 00111: val_evaluation_metric improved from 26.85195 to 27.03394, saving model to ./lstm_raw.h5\n",
      "Epoch 112/180\n",
      " - 7s - loss: 8203.0025 - evaluation_metric: 16.1624 - val_loss: 7294.4741 - val_evaluation_metric: 27.2235\n",
      "\n",
      "Epoch 00112: val_evaluation_metric improved from 27.03394 to 27.22355, saving model to ./lstm_raw.h5\n",
      "Epoch 113/180\n",
      " - 9s - loss: 8160.0151 - evaluation_metric: 16.1952 - val_loss: 7256.7766 - val_evaluation_metric: 27.4138\n",
      "\n",
      "Epoch 00113: val_evaluation_metric improved from 27.22355 to 27.41377, saving model to ./lstm_raw.h5\n",
      "Epoch 114/180\n",
      " - 9s - loss: 8125.6543 - evaluation_metric: 16.2337 - val_loss: 7218.6768 - val_evaluation_metric: 27.6125\n",
      "\n",
      "Epoch 00114: val_evaluation_metric improved from 27.41377 to 27.61253, saving model to ./lstm_raw.h5\n",
      "Epoch 115/180\n",
      " - 9s - loss: 8092.0487 - evaluation_metric: 16.2750 - val_loss: 7180.7847 - val_evaluation_metric: 27.8167\n",
      "\n",
      "Epoch 00115: val_evaluation_metric improved from 27.61253 to 27.81670, saving model to ./lstm_raw.h5\n",
      "Epoch 116/180\n",
      " - 9s - loss: 8054.6558 - evaluation_metric: 16.3329 - val_loss: 7142.7288 - val_evaluation_metric: 28.0283\n",
      "\n",
      "Epoch 00116: val_evaluation_metric improved from 27.81670 to 28.02829, saving model to ./lstm_raw.h5\n",
      "Epoch 117/180\n",
      " - 10s - loss: 8019.0078 - evaluation_metric: 16.3312 - val_loss: 7105.2910 - val_evaluation_metric: 28.1605\n",
      "\n",
      "Epoch 00117: val_evaluation_metric improved from 28.02829 to 28.16051, saving model to ./lstm_raw.h5\n",
      "Epoch 118/180\n",
      " - 10s - loss: 7982.1733 - evaluation_metric: 16.3060 - val_loss: 7067.8726 - val_evaluation_metric: 28.2849\n",
      "\n",
      "Epoch 00118: val_evaluation_metric improved from 28.16051 to 28.28489, saving model to ./lstm_raw.h5\n",
      "Epoch 119/180\n",
      " - 10s - loss: 7947.5207 - evaluation_metric: 16.2653 - val_loss: 7032.7505 - val_evaluation_metric: 28.4097\n",
      "\n",
      "Epoch 00119: val_evaluation_metric improved from 28.28489 to 28.40967, saving model to ./lstm_raw.h5\n",
      "Epoch 120/180\n",
      " - 9s - loss: 7911.6714 - evaluation_metric: 16.2219 - val_loss: 6998.0398 - val_evaluation_metric: 28.5405\n",
      "\n",
      "Epoch 00120: val_evaluation_metric improved from 28.40967 to 28.54054, saving model to ./lstm_raw.h5\n",
      "Epoch 121/180\n",
      " - 9s - loss: 7879.2946 - evaluation_metric: 16.2045 - val_loss: 6963.3669 - val_evaluation_metric: 28.6787\n",
      "\n",
      "Epoch 00121: val_evaluation_metric improved from 28.54054 to 28.67874, saving model to ./lstm_raw.h5\n",
      "Epoch 122/180\n",
      " - 10s - loss: 7850.3982 - evaluation_metric: 16.1647 - val_loss: 6928.3738 - val_evaluation_metric: 28.8257\n",
      "\n",
      "Epoch 00122: val_evaluation_metric improved from 28.67874 to 28.82573, saving model to ./lstm_raw.h5\n",
      "Epoch 123/180\n",
      " - 9s - loss: 7816.5979 - evaluation_metric: 16.1319 - val_loss: 6894.3015 - val_evaluation_metric: 28.9754\n",
      "\n",
      "Epoch 00123: val_evaluation_metric improved from 28.82573 to 28.97541, saving model to ./lstm_raw.h5\n",
      "Epoch 124/180\n",
      " - 9s - loss: 7779.0119 - evaluation_metric: 16.1418 - val_loss: 6860.1863 - val_evaluation_metric: 29.0522\n",
      "\n",
      "Epoch 00124: val_evaluation_metric improved from 28.97541 to 29.05218, saving model to ./lstm_raw.h5\n",
      "Epoch 125/180\n",
      " - 11s - loss: 7748.9673 - evaluation_metric: 16.1190 - val_loss: 6826.2935 - val_evaluation_metric: 29.1232\n",
      "\n",
      "Epoch 00125: val_evaluation_metric improved from 29.05218 to 29.12317, saving model to ./lstm_raw.h5\n",
      "Epoch 126/180\n",
      " - 11s - loss: 7716.8719 - evaluation_metric: 16.1328 - val_loss: 6792.0537 - val_evaluation_metric: 29.2037\n",
      "\n",
      "Epoch 00126: val_evaluation_metric improved from 29.12317 to 29.20373, saving model to ./lstm_raw.h5\n",
      "Epoch 127/180\n",
      " - 11s - loss: 7684.1779 - evaluation_metric: 16.1470 - val_loss: 6758.0703 - val_evaluation_metric: 29.2928\n",
      "\n",
      "Epoch 00127: val_evaluation_metric improved from 29.20373 to 29.29282, saving model to ./lstm_raw.h5\n",
      "Epoch 128/180\n",
      " - 11s - loss: 7656.2333 - evaluation_metric: 16.1628 - val_loss: 6725.0415 - val_evaluation_metric: 29.3880\n",
      "\n",
      "Epoch 00128: val_evaluation_metric improved from 29.29282 to 29.38803, saving model to ./lstm_raw.h5\n",
      "Epoch 129/180\n",
      " - 8s - loss: 7626.6304 - evaluation_metric: 16.1657 - val_loss: 6693.7759 - val_evaluation_metric: 29.4859\n",
      "\n",
      "Epoch 00129: val_evaluation_metric improved from 29.38803 to 29.48592, saving model to ./lstm_raw.h5\n",
      "Epoch 130/180\n",
      " - 7s - loss: 7593.7240 - evaluation_metric: 16.1818 - val_loss: 6662.7898 - val_evaluation_metric: 29.5903\n",
      "\n",
      "Epoch 00130: val_evaluation_metric improved from 29.48592 to 29.59033, saving model to ./lstm_raw.h5\n",
      "Epoch 131/180\n",
      " - 8s - loss: 7560.7364 - evaluation_metric: 16.2155 - val_loss: 6630.5361 - val_evaluation_metric: 29.7054\n",
      "\n",
      "Epoch 00131: val_evaluation_metric improved from 29.59033 to 29.70538, saving model to ./lstm_raw.h5\n",
      "Epoch 132/180\n",
      " - 8s - loss: 7532.8880 - evaluation_metric: 16.2409 - val_loss: 6598.5164 - val_evaluation_metric: 29.8273\n",
      "\n",
      "Epoch 00132: val_evaluation_metric improved from 29.70538 to 29.82726, saving model to ./lstm_raw.h5\n",
      "Epoch 133/180\n",
      " - 8s - loss: 7499.0945 - evaluation_metric: 16.2719 - val_loss: 6566.6672 - val_evaluation_metric: 29.9561\n",
      "\n",
      "Epoch 00133: val_evaluation_metric improved from 29.82726 to 29.95615, saving model to ./lstm_raw.h5\n",
      "Epoch 134/180\n",
      " - 8s - loss: 7469.8854 - evaluation_metric: 16.3059 - val_loss: 6535.1716 - val_evaluation_metric: 30.0911\n",
      "\n",
      "Epoch 00134: val_evaluation_metric improved from 29.95615 to 30.09107, saving model to ./lstm_raw.h5\n",
      "Epoch 135/180\n",
      " - 7s - loss: 7445.9636 - evaluation_metric: 16.3320 - val_loss: 6502.8025 - val_evaluation_metric: 30.1501\n",
      "\n",
      "Epoch 00135: val_evaluation_metric improved from 30.09107 to 30.15005, saving model to ./lstm_raw.h5\n",
      "Epoch 136/180\n",
      " - 8s - loss: 7416.9028 - evaluation_metric: 16.2945 - val_loss: 6470.4685 - val_evaluation_metric: 30.2135\n",
      "\n",
      "Epoch 00136: val_evaluation_metric improved from 30.15005 to 30.21353, saving model to ./lstm_raw.h5\n",
      "Epoch 137/180\n",
      " - 8s - loss: 7383.0319 - evaluation_metric: 16.2205 - val_loss: 6439.0605 - val_evaluation_metric: 30.2846\n",
      "\n",
      "Epoch 00137: val_evaluation_metric improved from 30.21353 to 30.28461, saving model to ./lstm_raw.h5\n",
      "Epoch 138/180\n",
      " - 9s - loss: 7349.8805 - evaluation_metric: 16.1912 - val_loss: 6410.3027 - val_evaluation_metric: 30.3577\n",
      "\n",
      "Epoch 00138: val_evaluation_metric improved from 30.28461 to 30.35773, saving model to ./lstm_raw.h5\n",
      "Epoch 139/180\n",
      " - 8s - loss: 7324.2212 - evaluation_metric: 16.1765 - val_loss: 6381.0789 - val_evaluation_metric: 30.4398\n",
      "\n",
      "Epoch 00139: val_evaluation_metric improved from 30.35773 to 30.43985, saving model to ./lstm_raw.h5\n",
      "Epoch 140/180\n",
      " - 7s - loss: 7300.1156 - evaluation_metric: 16.1838 - val_loss: 6351.0002 - val_evaluation_metric: 30.5325\n",
      "\n",
      "Epoch 00140: val_evaluation_metric improved from 30.43985 to 30.53252, saving model to ./lstm_raw.h5\n",
      "Epoch 141/180\n",
      " - 8s - loss: 7269.8693 - evaluation_metric: 16.1343 - val_loss: 6320.4153 - val_evaluation_metric: 30.6352\n",
      "\n",
      "Epoch 00141: val_evaluation_metric improved from 30.53252 to 30.63516, saving model to ./lstm_raw.h5\n",
      "Epoch 142/180\n",
      " - 10s - loss: 7242.1697 - evaluation_metric: 16.1049 - val_loss: 6290.7937 - val_evaluation_metric: 30.6960\n",
      "\n",
      "Epoch 00142: val_evaluation_metric improved from 30.63516 to 30.69601, saving model to ./lstm_raw.h5\n",
      "Epoch 143/180\n",
      " - 9s - loss: 7216.4757 - evaluation_metric: 16.1022 - val_loss: 6260.6401 - val_evaluation_metric: 30.7244\n",
      "\n",
      "Epoch 00143: val_evaluation_metric improved from 30.69601 to 30.72437, saving model to ./lstm_raw.h5\n",
      "Epoch 144/180\n",
      " - 10s - loss: 7185.4570 - evaluation_metric: 16.1273 - val_loss: 6231.2222 - val_evaluation_metric: 30.7610\n",
      "\n",
      "Epoch 00144: val_evaluation_metric improved from 30.72437 to 30.76098, saving model to ./lstm_raw.h5\n",
      "Epoch 145/180\n",
      " - 9s - loss: 7156.7995 - evaluation_metric: 16.1002 - val_loss: 6202.1807 - val_evaluation_metric: 30.8064\n",
      "\n",
      "Epoch 00145: val_evaluation_metric improved from 30.76098 to 30.80644, saving model to ./lstm_raw.h5\n",
      "Epoch 146/180\n",
      " - 8s - loss: 7133.4389 - evaluation_metric: 16.1396 - val_loss: 6171.7908 - val_evaluation_metric: 30.8638\n",
      "\n",
      "Epoch 00146: val_evaluation_metric improved from 30.80644 to 30.86381, saving model to ./lstm_raw.h5\n",
      "Epoch 147/180\n",
      " - 7s - loss: 7098.0830 - evaluation_metric: 16.1165 - val_loss: 6141.0305 - val_evaluation_metric: 30.9320\n",
      "\n",
      "Epoch 00147: val_evaluation_metric improved from 30.86381 to 30.93197, saving model to ./lstm_raw.h5\n",
      "Epoch 148/180\n",
      " - 9s - loss: 7069.4096 - evaluation_metric: 16.1372 - val_loss: 6111.9912 - val_evaluation_metric: 31.0056\n",
      "\n",
      "Epoch 00148: val_evaluation_metric improved from 30.93197 to 31.00555, saving model to ./lstm_raw.h5\n",
      "Epoch 149/180\n",
      " - 9s - loss: 7044.0818 - evaluation_metric: 16.1942 - val_loss: 6082.7148 - val_evaluation_metric: 31.0880\n",
      "\n",
      "Epoch 00149: val_evaluation_metric improved from 31.00555 to 31.08795, saving model to ./lstm_raw.h5\n",
      "Epoch 150/180\n",
      " - 9s - loss: 7014.3395 - evaluation_metric: 16.2201 - val_loss: 6054.0354 - val_evaluation_metric: 31.1758\n",
      "\n",
      "Epoch 00150: val_evaluation_metric improved from 31.08795 to 31.17580, saving model to ./lstm_raw.h5\n",
      "Epoch 151/180\n",
      " - 11s - loss: 6987.4002 - evaluation_metric: 16.2523 - val_loss: 6024.6294 - val_evaluation_metric: 31.2744\n",
      "\n",
      "Epoch 00151: val_evaluation_metric improved from 31.17580 to 31.27444, saving model to ./lstm_raw.h5\n",
      "Epoch 152/180\n",
      " - 11s - loss: 6957.6301 - evaluation_metric: 16.2646 - val_loss: 5994.9158 - val_evaluation_metric: 31.3832\n",
      "\n",
      "Epoch 00152: val_evaluation_metric improved from 31.27444 to 31.38319, saving model to ./lstm_raw.h5\n",
      "Epoch 153/180\n",
      " - 10s - loss: 6933.4634 - evaluation_metric: 16.3211 - val_loss: 5965.7793 - val_evaluation_metric: 31.4537\n",
      "\n",
      "Epoch 00153: val_evaluation_metric improved from 31.38319 to 31.45374, saving model to ./lstm_raw.h5\n",
      "Epoch 154/180\n",
      " - 11s - loss: 6903.5222 - evaluation_metric: 16.2852 - val_loss: 5937.7573 - val_evaluation_metric: 31.4870\n",
      "\n",
      "Epoch 00154: val_evaluation_metric improved from 31.45374 to 31.48704, saving model to ./lstm_raw.h5\n",
      "Epoch 155/180\n",
      " - 11s - loss: 6879.5565 - evaluation_metric: 16.2370 - val_loss: 5910.8638 - val_evaluation_metric: 31.5274\n",
      "\n",
      "Epoch 00155: val_evaluation_metric improved from 31.48704 to 31.52742, saving model to ./lstm_raw.h5\n",
      "Epoch 156/180\n",
      " - 9s - loss: 6852.2855 - evaluation_metric: 16.2185 - val_loss: 5884.3804 - val_evaluation_metric: 31.5760\n",
      "\n",
      "Epoch 00156: val_evaluation_metric improved from 31.52742 to 31.57596, saving model to ./lstm_raw.h5\n",
      "Epoch 157/180\n",
      " - 7s - loss: 6831.8624 - evaluation_metric: 16.1770 - val_loss: 5856.9683 - val_evaluation_metric: 31.6353\n",
      "\n",
      "Epoch 00157: val_evaluation_metric improved from 31.57596 to 31.63532, saving model to ./lstm_raw.h5\n",
      "Epoch 158/180\n",
      " - 8s - loss: 6801.3273 - evaluation_metric: 16.1693 - val_loss: 5830.6233 - val_evaluation_metric: 31.7010\n",
      "\n",
      "Epoch 00158: val_evaluation_metric improved from 31.63532 to 31.70102, saving model to ./lstm_raw.h5\n",
      "Epoch 159/180\n",
      " - 7s - loss: 6784.0539 - evaluation_metric: 16.1120 - val_loss: 5803.7886 - val_evaluation_metric: 31.7766\n",
      "\n",
      "Epoch 00159: val_evaluation_metric improved from 31.70102 to 31.77659, saving model to ./lstm_raw.h5\n",
      "Epoch 160/180\n",
      " - 9s - loss: 6755.8590 - evaluation_metric: 16.1136 - val_loss: 5778.5239 - val_evaluation_metric: 31.8556\n",
      "\n",
      "Epoch 00160: val_evaluation_metric improved from 31.77659 to 31.85564, saving model to ./lstm_raw.h5\n",
      "Epoch 161/180\n",
      " - 7s - loss: 6726.9787 - evaluation_metric: 16.1296 - val_loss: 5752.7395 - val_evaluation_metric: 31.8800\n",
      "\n",
      "Epoch 00161: val_evaluation_metric improved from 31.85564 to 31.88001, saving model to ./lstm_raw.h5\n",
      "Epoch 162/180\n",
      " - 8s - loss: 6708.3012 - evaluation_metric: 16.1013 - val_loss: 5726.4675 - val_evaluation_metric: 31.8935\n",
      "\n",
      "Epoch 00162: val_evaluation_metric improved from 31.88001 to 31.89346, saving model to ./lstm_raw.h5\n",
      "Epoch 163/180\n",
      " - 8s - loss: 6681.3380 - evaluation_metric: 16.1054 - val_loss: 5701.4636 - val_evaluation_metric: 31.9148\n",
      "\n",
      "Epoch 00163: val_evaluation_metric improved from 31.89346 to 31.91478, saving model to ./lstm_raw.h5\n",
      "Epoch 164/180\n",
      " - 7s - loss: 6660.5547 - evaluation_metric: 16.1349 - val_loss: 5676.5889 - val_evaluation_metric: 31.9448\n",
      "\n",
      "Epoch 00164: val_evaluation_metric improved from 31.91478 to 31.94485, saving model to ./lstm_raw.h5\n",
      "Epoch 165/180\n",
      " - 8s - loss: 6633.8741 - evaluation_metric: 16.1174 - val_loss: 5652.1409 - val_evaluation_metric: 31.9829\n",
      "\n",
      "Epoch 00165: val_evaluation_metric improved from 31.94485 to 31.98291, saving model to ./lstm_raw.h5\n",
      "Epoch 166/180\n",
      " - 7s - loss: 6609.2666 - evaluation_metric: 16.1390 - val_loss: 5628.3267 - val_evaluation_metric: 32.0280\n",
      "\n",
      "Epoch 00166: val_evaluation_metric improved from 31.98291 to 32.02803, saving model to ./lstm_raw.h5\n",
      "Epoch 167/180\n",
      " - 8s - loss: 6588.8393 - evaluation_metric: 16.1607 - val_loss: 5603.0786 - val_evaluation_metric: 32.0845\n",
      "\n",
      "Epoch 00167: val_evaluation_metric improved from 32.02803 to 32.08446, saving model to ./lstm_raw.h5\n",
      "Epoch 168/180\n",
      " - 7s - loss: 6566.4609 - evaluation_metric: 16.1967 - val_loss: 5577.0129 - val_evaluation_metric: 32.1519\n",
      "\n",
      "Epoch 00168: val_evaluation_metric improved from 32.08446 to 32.15193, saving model to ./lstm_raw.h5\n",
      "Epoch 169/180\n",
      " - 8s - loss: 6541.1823 - evaluation_metric: 16.1778 - val_loss: 5552.6365 - val_evaluation_metric: 32.2234\n",
      "\n",
      "Epoch 00169: val_evaluation_metric improved from 32.15193 to 32.22343, saving model to ./lstm_raw.h5\n",
      "Epoch 170/180\n",
      " - 9s - loss: 6517.2424 - evaluation_metric: 16.2506 - val_loss: 5527.7002 - val_evaluation_metric: 32.3039\n",
      "\n",
      "Epoch 00170: val_evaluation_metric improved from 32.22343 to 32.30389, saving model to ./lstm_raw.h5\n",
      "Epoch 171/180\n",
      " - 8s - loss: 6494.7883 - evaluation_metric: 16.2583 - val_loss: 5502.7268 - val_evaluation_metric: 32.3925\n",
      "\n",
      "Epoch 00171: val_evaluation_metric improved from 32.30389 to 32.39250, saving model to ./lstm_raw.h5\n",
      "Epoch 172/180\n",
      " - 8s - loss: 6475.0342 - evaluation_metric: 16.2966 - val_loss: 5479.0160 - val_evaluation_metric: 32.4844\n",
      "\n",
      "Epoch 00172: val_evaluation_metric improved from 32.39250 to 32.48438, saving model to ./lstm_raw.h5\n",
      "Epoch 173/180\n",
      " - 9s - loss: 6450.7048 - evaluation_metric: 16.3096 - val_loss: 5454.0771 - val_evaluation_metric: 32.5135\n",
      "\n",
      "Epoch 00173: val_evaluation_metric improved from 32.48438 to 32.51350, saving model to ./lstm_raw.h5\n",
      "Epoch 174/180\n",
      " - 8s - loss: 6427.4045 - evaluation_metric: 16.2416 - val_loss: 5429.9738 - val_evaluation_metric: 32.5408\n",
      "\n",
      "Epoch 00174: val_evaluation_metric improved from 32.51350 to 32.54082, saving model to ./lstm_raw.h5\n",
      "Epoch 175/180\n",
      " - 7s - loss: 6403.8388 - evaluation_metric: 16.2247 - val_loss: 5406.7415 - val_evaluation_metric: 32.5749\n",
      "\n",
      "Epoch 00175: val_evaluation_metric improved from 32.54082 to 32.57488, saving model to ./lstm_raw.h5\n",
      "Epoch 176/180\n",
      " - 6s - loss: 6383.8005 - evaluation_metric: 16.2007 - val_loss: 5383.6484 - val_evaluation_metric: 32.6173\n",
      "\n",
      "Epoch 00176: val_evaluation_metric improved from 32.57488 to 32.61731, saving model to ./lstm_raw.h5\n",
      "Epoch 177/180\n",
      " - 7s - loss: 6362.9322 - evaluation_metric: 16.1745 - val_loss: 5361.3752 - val_evaluation_metric: 32.5964\n",
      "\n",
      "Epoch 00177: val_evaluation_metric did not improve from 32.61731\n",
      "Epoch 178/180\n",
      " - 6s - loss: 6338.8386 - evaluation_metric: 16.1304 - val_loss: 5338.4771 - val_evaluation_metric: 32.5760\n",
      "\n",
      "Epoch 00178: val_evaluation_metric did not improve from 32.61731\n",
      "Epoch 179/180\n",
      " - 7s - loss: 6316.5541 - evaluation_metric: 16.1180 - val_loss: 5315.5193 - val_evaluation_metric: 32.5646\n",
      "\n",
      "Epoch 00179: val_evaluation_metric did not improve from 32.61731\n",
      "Epoch 180/180\n",
      " - 7s - loss: 6298.0048 - evaluation_metric: 16.1029 - val_loss: 5293.0656 - val_evaluation_metric: 32.5629\n",
      "\n",
      "Epoch 00180: val_evaluation_metric did not improve from 32.61731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa54c41a1d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=\"./lstm_raw.h5\",monitor='val_evaluation_metric',verbose=1,save_best_only='True',\n",
    "                             mode='max',period=1)\n",
    "# tensorboard = TensorBoard(log_dir='log(./)')\n",
    "callback_lists = [checkpoint]  #因为callback是list型,必须转化为list\n",
    "graph = tf.get_default_graph()\n",
    "model=LSTM_model((60,25600))\n",
    "model.summary()\n",
    "Adam = optimizers.Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam,metrics=[evaluation_metric])\n",
    "# model.compile(loss=cust_loss2, optimizer=Adam,metrics=[evaluation_metric])\n",
    "model.fit(train_data,train_label, epochs=2000, verbose=2,batch_size=25,validation_data=(valid_data, valid_label),callbacks=callback_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('lstm_raw_fft.h5',{\"evaluation_metric\":evaluation_metric})\n",
    "model = load_model('lstm_raw.h5',{\"evaluation_metric\":evaluation_metric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicted=model.predict(train_fft_data).reshape(-1,)\n",
    "predicted=model.predict(train_data).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.150347765327\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwEGSJHXs/wNBceNxEn0FpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1dad793e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result=pd.DataFrame({\"real\":train_label.reshape(-1,),\"predicted\":predicted})\n",
    "df_predict=df_result[\"predicted\"].groupby(df_result['real']).mean()\n",
    "err=Error_compute(df_predict.index,df_predict)\n",
    "print(err)\n",
    "plt_plot(df_predict.index,df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a=data_generator(train_data_list_pool,label_data_list_pool,source_dire_list,batch_size=5,time_range=1)\n",
    "i=1\n",
    "for data ,label in a:\n",
    "    print(data.shape,label.shape)\n",
    "    print(i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration.values,60\n",
    "def get_train_data_list_pool(data_dire_list):#获得多个文件夹中的源数据\n",
    "    train_data_list_pool=[]\n",
    "    label_data_list_pool=[]# source data from mutiply floder \n",
    "    for data_dire in data_dire_list:\n",
    "        file_dire=os.path.join(data_dire,'Sensor')\n",
    "        file_list_length=len(os.listdir(file_dire))\n",
    "        train_data_pool_list=[]\n",
    "        label_data_pool_list=[]\n",
    "        for file_index in range(1,file_list_length+1):\n",
    "            residual_life_list=[]\n",
    "            df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "            df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "            residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "            label_data_pool_list.append(residual_life_list)\n",
    "            train_data_pool_list.append(df_60s)\n",
    "        train_data_list_pool.append(train_data_pool_list)\n",
    "        label_data_list_pool.append(label_data_pool_list)\n",
    "    return train_data_list_pool,label_data_list_pool\n",
    "\n",
    "def data_generator(train_data_list_pool,label_data_list_pool,data_dire_list,batch_size=5,time_range=1):\n",
    "#     train_data_list_pool,label_data_list_pool=get_train_data_list_pool(data_dire_list)\n",
    "    \n",
    "    file_list_length=0#获得一个epoch中每个batch需要输出的所有随机样本序列号\n",
    "    for train_data_list in train_data_list_pool:\n",
    "        file_list_length=file_list_length+len(train_data_list)-time_range\n",
    "    batch_random_list_epoch=list(range(1,(file_list_length+1)))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    exit()\n",
    "    for i in range((file_list_length)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "#         label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]#某batch需要输出的样本序列号\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            \n",
    "            upper_bound_file_num=0                               #确定从第几个文件夹中获取数据\n",
    "            lower_bound_file_num=0\n",
    "            for floder_index in range(len(train_data_list_pool)):\n",
    "                upper_bound_file_num=upper_bound_file_num+len(train_data_list_pool[floder_index])-time_range\n",
    "                if start_index<=upper_bound_file_num:\n",
    "                    for minute_index in range(start_index,start_index+time_range):#将time_range分钟的数据连接在一起\n",
    "#                         print(\"floder_index,file_index\",floder_index,minute_index-lower_bound_file_num)\n",
    "                        df_60s=train_data_list_pool[floder_index][minute_index-1-lower_bound_file_num]\n",
    "                        reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                        signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                        residual_life_list.extend(label_data_list_pool[floder_index][minute_index-1-lower_bound_file_num])\n",
    "                    break\n",
    "                lower_bound_file_num=lower_bound_file_num+len(train_data_list_pool[floder_index])-time_range\n",
    "                \n",
    "            resudual_life_array = np.array(residual_life_list)#把上一步中得到的time_range分钟数据作为一条样本加到一个batch组中\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "            label_data=label_data.reshape(-1,60,)\n",
    "            gc.collect()\n",
    "            yield train_data,label_data\n",
    "#         for data,label in zip(train_data,label_data):\n",
    "#             yield data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(range(len(df_signal[\"vibration_1\"])),df_signal[\"vibration_1\"], color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_dire=os.path.join(source_dire,'0'+str(1),'Sensor')\n",
    "file_list_length=len(os.listdir(file_dire))\n",
    "for file_index in range(1,file_list_length+1):\n",
    "    df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "    print(file_index,df_signal.shape)\n",
    "\n",
    "df_signal=pd.read_csv(os.path.join(file_dire,str(13)+\".csv\"))\n",
    "if df_signal.shape[0]<1536000:\n",
    "    zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "    df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "df_signal=df_signal.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequence_data_generator(data_dire,batch_size=5,time_range=1,dire_index=1):\n",
    "    file_dire=os.path.join(data_dire,'0'+str(dire_index),'Sensor')\n",
    "    file_list_length=len(os.listdir(file_dire))\n",
    "    batch_random_list_epoch=list(range(1,file_list_length+1-time_range))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    for i in range((file_list_length+1-time_range)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            for file_index in range(start_index,start_index+time_range):\n",
    "                df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "                df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "                reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "            resudual_life_array = np.array(residual_life_list)\n",
    "            gc.collect()\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "        yield train_data,label_data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def window1sDataCut(df_signal):\n",
    "    if df_signal.shape[0]<1536000:#padding 0 when length less 1536000\n",
    "        zero_data = np.zeros(shape=(1536000-df_signal.shape[0],4))\n",
    "        df_temp = pd.DataFrame(zero_data, columns=df_signal.columns)\n",
    "        df_raw_vibration=df_signal.append(df_temp)\n",
    "    else:\n",
    "        df_raw_vibration=df_signal\n",
    "    \n",
    "    df_raw_vibration_length = df_raw_vibration.shape[0]# cut head and tail when length more than 1536000\n",
    "    delete_length = df_raw_vibration_length % 25600\n",
    "    df_vibration = df_raw_vibration[delete_length//2 : (delete_length//2)+(25600*60)]\n",
    "    print(\"after cut:\",df_vibration.shape,60)\n",
    "    return df_vibration,60\n",
    "def get_train_data_pool(data_dire,dire_index=1):\n",
    "    file_dire=os.path.join(data_dire,'0'+str(dire_index),'Sensor')\n",
    "    file_list_length=len(os.listdir(file_dire))\n",
    "    train_data_pool_list=[]\n",
    "    label_data_pool_list=[]\n",
    "    for file_index in range(1,file_list_length+1):\n",
    "        residual_life_list=[]\n",
    "        df_signal=pd.read_csv(os.path.join(file_dire,str(file_index)+\".csv\"))\n",
    "        df_60s,seconds_counts=window1sDataCut(df_signal)\n",
    "        residual_life_list.extend([(file_list_length-file_index)*5]*seconds_counts)\n",
    "        label_data_pool_list.append(residual_life_list)\n",
    "        train_data_pool_list.append(df_60s)\n",
    "    return train_data_pool_list,label_data_pool_list    \n",
    "def sequence_data_generator_load_memary(data_dire,batch_size=5,time_range=1,dire_index=1):\n",
    "    train_data_pool_list,label_data_pool_list=get_train_data_pool(data_dire)\n",
    "    file_list_length=len(train_data_pool_list)\n",
    "    batch_random_list_epoch=list(range(1,file_list_length+1-time_range))\n",
    "    np.random.shuffle(batch_random_list_epoch)\n",
    "    for i in range((file_list_length+1-time_range)//batch_size):\n",
    "        train_data=np.array([]).reshape(-1,60*time_range,25600)\n",
    "        label_data=np.array([]).reshape(-1,60*time_range,1)\n",
    "        batch_random_list=batch_random_list_epoch[batch_size*i:batch_size*(i+1)]\n",
    "\n",
    "        for start_index in batch_random_list:\n",
    "            signal_array=np.array([]).reshape(-1,25600)\n",
    "            residual_life_list=[]\n",
    "            for file_index in range(start_index,start_index+time_range):\n",
    "                df_60s=train_data_pool_list[file_index-1]\n",
    "                reshape_data = df_60s['vibration_1'].values.reshape(-1, 25600)\n",
    "                signal_array = np.append(signal_array,reshape_data,axis=0)\n",
    "                residual_life_list.extend(label_data_pool_list[file_index-1])\n",
    "            resudual_life_array = np.array(residual_life_list)\n",
    "            signal_array=signal_array.reshape(-1,60*time_range,25600)\n",
    "            resudual_life_array=resudual_life_array.reshape(-1,60*time_range,1)\n",
    "            train_data=np.append(train_data,signal_array,axis=0)\n",
    "            label_data=np.append(label_data,resudual_life_array,axis=0)\n",
    "            gc.collect()\n",
    "        yield train_data,label_data     "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
